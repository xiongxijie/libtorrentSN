
#include "Utils.h"
#include "BaconVideoWidget.h"





/*gstreamer*/

#define GST_USE_UNSTABLE_API 1

#include <gst/gst.h>
#include <gst/gstpad.h> 
#include <gst/gstcaps.h> 

/* GStreamer Interfaces */
#include <gst/video/colorbalance.h>
/* for detecting sources of errors */
#include <gst/video/gstvideosink.h>
#include <gst/video/video.h>
#include <gst/audio/audio.h>
#include <gst/audio/streamvolume.h>
/* for missing decoder/demuxer detection */
#include <gst/pbutils/pbutils.h>
/* for the cover metadata info */
#include <gst/tag/tag.h>


#include "TotemGstHelper.h" // for totem_gst_message_print()


#ifdef __cplusplus
extern "C" {
#endif
#include "bacon-video-widget-enums.h"//header generated by glib-mkenums
#include "bacon-video-widget-resources.h"//resource generated by glib-compile-resources
#ifdef __cplusplus
}
#endif

#include <iostream>
#include <cstdint>  // Required for std::int64_t
#include <stdio.h>

/* Helper constants */
#define NANOSECS_IN_SEC 1000000000
#define SEEK_TIMEOUT NANOSECS_IN_SEC / 10
#define FORWARD_RATE 1.0
#define REVERSE_RATE -1.0
#define DIRECTION_STR (forward == FALSE ? "reverse" : "forward")


enum StreamType
{
  STREAM_TYPE_AUDIO,
  STREAM_TYPE_VIDEO,
};


#define is_error(e, d, c) \
  (e->domain == GST_##d##_ERROR && \
   e->code == GST_##d##_ERROR_##c)


// register GST debugging category, so we can use GST_DEBUG("some-msg")...without needing to run GST_DEBUG(_totem_gst_debug_cat, "some-msg")
GST_DEBUG_CATEGORY (_trtotem_gst_debug_cat);
#define GST_CAT_DEFAULT _trtotem_gst_debug_cat



//GError domain register
GQuark
bacon_video_widget_error_quark (void)
{
  static GQuark q; /* 0 */

  if (G_UNLIKELY (q == 0)) {
    q = g_quark_from_static_string ("bvw-error-quark");
  }
  return q;
}





class BaconVideoWidget::Impl
{
    public:
        Impl(BaconVideoWidget& widget);
        ~Impl();

        TR_DISABLE_COPY_MOVE(Impl)


        GObject* fetch_btdemux();
        
        bool check_gstreamer_init(Glib::Error& error);
        bool check_pipeline_init(Glib::Error& error);

        BvwRotation get_rotation();
        void set_rotation(BvwRotation rotation);
        bool set_rate(float rate);
        void set_aspect_ratio(BvwAspectRatio ratio);

        gint64 update_and_get_stream_length();

        gint64 get_current_time();

        void get_metadata(BvwMetadataType type, Glib::ValueBase& value);

        bool is_playing();

        void open(int fileidx);
        bool play(GError ** error);
        void pause();
        void stop();
        void close();

        bool update_and_get_seekable();
        bool seek_time(std::int64_t _time, bool accurate, GError **error);
        bool can_direct_seek();
        bool seek(double position, GError **error);

        bool can_set_volume();
        void set_volume(double volume);
        double get_volume();

        void set_show_cursor(bool show_cursor);

        //exposed properties
        Glib::Property<double>& property_volume();
        Glib::Property<bool>& property_seekable();
        Glib::Property<std::string>& property_audio_output_type();


        Glib::Property<int>& property_color_balance_contrast();
        Glib::Property<int>& property_color_balance_saturation();
        Glib::Property<int>& property_color_balance_brightness();
        Glib::Property<int>& property_color_balance_hue();

        // exposed signal
        sigc::signal<void(const char*, bool)>& signal_error();
        sigc::signal<void()>& signal_eos();
        sigc::signal<void(std::int64_t, std::int64_t, double, bool)>& signal_tick();
        sigc::signal<void()>& signal_play_starting();
        sigc::signal<void()>& signal_got_metadata();
        sigc::signal<void()>& signal_btdemux_destructing();


    private:
        template<typename T>
        T* get_template_child(char const* name) const;
        

        void on_realize_behavior();

        void on_unrealize_behavior();

        bool trigger_unrealize_behavior();

        /* Internally used methods */
        void update_cursor();

        void set_current_actor();

        static gboolean is_feature_enabled (const char *env);
        static GstElement* element_make_or_warn (const char *plugin, const char *name);

        void clear_missing_plugins_messages();
        GError* bvw_error_from_gst_error(GstMessage * err_msg);
        void show_error_if_video_decoder_is_missing();
        void check_if_video_decoder_is_missing ();
        bool check_missing_plugins_error(GstMessage * err_msg);
        bool check_mpeg_eos(GstMessage *err_msg);

        void handle_application_message(GstMessage *msg);
        void handle_element_message(GstMessage *msg);

        GstColorBalanceChannel* get_color_balance_channel(GstColorBalance* color_balance, BvwVideoProperty type);
        int get_video_property(BvwVideoProperty type);
        void set_video_property(BvwVideoProperty type, int value);
        void set_color_balance_contrast();
        void set_color_balance_saturation();
        void set_color_balance_brightness();
        void set_color_balance_hue();

        gint get_num_audio_channels();
        GstCaps * fixate_to_num(const GstCaps * in_caps, gint channels);
        void set_audio_filter();
        void set_audio_output_type(BvwAudioOutputType type);
        void on_audio_output_type_changed();

        void get_metadata_string (BvwMetadataType type, Glib::ValueBase& value);
        void get_metadata_int (BvwMetadataType type, Glib::ValueBase& value);
        void get_metadata_bool (BvwMetadataType type, Glib::ValueBase& value);

        void stop_play_pipeline();

        bool set_playback_direction(bool forward);

        bool seek_time_no_lock(gint64 _time, GstSeekFlags flag, GError **error);


        //for Gsteamer callback, pass user_data as this pointer
        static void on_pad_added_function(GstElement* decodebin, GstPad* pad, gpointer user_data);
        void on_pad_added_method(GstElement* decodebin, GstPad* pad);
        
        static void on_pad_removed_function(GstElement* decodebin, GstPad* pad, gpointer user_data);
        void on_pad_removed_method(GstElement* decodebin, GstPad* pad);

        static void on_btdemux_pad_added_function(GstElement *element, GstPad *pad, gpointer user_data);
        void on_btdemux_pad_added_method(GstElement* element, GstPad* pad);


        static void on_btdemux_pad_removed_function(GstElement *element, GstPad *pad, gpointer user_data);
        void on_btdemux_pad_removed_method(GstElement* element, GstPad* pad);


        static void on_btdemux_no_more_pads_function(GstElement *element, gpointer user_data);
        void on_btdemux_no_more_pads_method(GstElement* element);


        static void bus_message_cb_function(GstBus * bus, GstMessage * message, gpointer user_data);
        void bus_message_cb_method(GstBus * bus, GstMessage * message);

        static void caps_set_function(GObject * obj, GParamSpec * pspec, gpointer user_data);
        void caps_set_method (GObject * obj);

        static gboolean decodebin_audio_outpad_event_function(GstPad * pad, GstObject * parent, GstEvent * event);
        void decodebin_audio_outpad_event_method(GstEvent * event);

        static gboolean decodebin_video_outpad_event_function(GstPad * pad, GstObject * parent, GstEvent * event);
        void decodebin_video_outpad_event_method(GstEvent * event);


        void update_stream_info();
        void parse_stream_info();

        bool volume_readback_cb();
        void volume_readback();

        gboolean audio_caps_have_LFE(GstStructure* s);
        GstCaps * get_caps_of_current_stream(StreamType type);
        gint get_current_stream_num(StreamType stream_type);
        GstTagList* get_tags_of_current_stream(StreamType stream_type);

        void update_tags(GstTagList *tags, StreamType type);

        bool signal_eos_delayed();

        bool query_timeout();
        void reconfigure_tick_timeout(guint msecs);
        void got_time_tick(GstElement * element, gint64 time_nanos);

        void handle_buffering_message(GstMessage * message);

        void bvw_gstreamer_pipeline_cleanup();

    private:        
        BaconVideoWidget& widget_;
        
        /* Widgets loaded from template */
        Gtk::Stack                    *stack_ = nullptr;
        Gtk::Image                    *audio_only_ = nullptr;//one page of stack, name is "audio-only"
        Gtk::Image                    *broken_video_ = nullptr;//one page of stack, name is "broken-video"
        Gtk::Widget                   *video_widget_ = nullptr;//fetched from [gstgtkglsink] plugin in GStreamer
        Gtk::Window                   *parent_toplevel_ = nullptr;//Actually the MyHdyApplicationWindow

        //don't need to manually free or unref the Glib::Error object, as it will handle cleanup for you
        Glib::Error                   init_error_ = {};
        Glib::Error                   gst_init_errors_ = {};

        gboolean                     buffering_ = false;
        gboolean                     cursor_shown_ = true;
        gboolean                     media_has_video_ = false;
        gboolean                     media_has_unsupported_video_ = false;
        gboolean                     media_has_audio_ = false;
        gint                         seekable_ = -1; /* -1 = don't know, FALSE = no */
        gint64                       stream_length_ = 0;/*0 = not set yet*/
        gint64                       current_time_ = 0;
        gint64                       seek_time_ = -1;
        gdouble                      current_position_ = 0;
        int                          cur_video_fileidx_within_tor_ = -1;
        gint                         stream_id_seq_ = 0;
        gint                         video_width_ = 0; /* Movie width */
        gint                         video_height_ = 0; /* Movie height */
        gint                         video_fps_n_ = 0;
        gint                         video_fps_d_ = 0;
        gulong                       sig_bus_async_ = 0;
        float                        rate_ = FORWARD_RATE;
        BvwAspectRatio               ratio_type_ = BVW_RATIO_AUTO;
        BvwRotation                  rotation_ = BVW_ROTATION_R_ZERO;
        BvwAudioOutputType           speakersetup_ = BVW_AUDIO_SOUND_STEREO;


        GstElement                    *pipeline_ = nullptr;
        GstElement                    *btdemux_ = nullptr;
        GstElement                    *decodebin_ = nullptr;
        GstElement                    *audio_bin_ = nullptr;
        GstElement                    *glsinkbin_ = nullptr;
        GstElement                    *video_sink_ = nullptr;
        GstElement                    *audio_filter_convert_ = nullptr;
        GstElement                    *audio_capsfilter_ = nullptr;
        GstElement                    *audio_pitchcontrol_ = nullptr;
        GstElement                    *volume_plugin_ = nullptr;
        GstElement                    *audio_sink_ = nullptr;
        GstPad                        *video_sinpad_decodebin_ = nullptr;
        GstPad                        *audio_sinpad_decodebin_ = nullptr;

    
        GPtrArray                     *video_channels_ = nullptr; 
        GPtrArray                     *audio_channels_ = nullptr; 
        GPtrArray                     *btdemux_srcpads_ = nullptr;
        

        GstBus                       *bus_ = nullptr;
        /* state we want to be in, as opposed to actual pipeline state
        * which may change asynchronously or during buffering */
        GstState                     target_state_;

        /* When seeking, queue up the seeks if they happen before
          * the previous one finished */
        GMutex                       seek_mutex_;
        GstClock                     *clock_ = nullptr;
        GstClockTime                 seek_req_time_ = GST_CLOCK_TIME_NONE;

        GstTagList                  *tagcache_ = nullptr;

        /* for missing codecs handling */
        GList                       *missing_plugins_ = nullptr;   /* GList of GstMessages */

        // Exposed properties
        Glib::Property<bool> property_seekable_;
        Glib::Property<double> property_volume_;
        Glib::Property<std::string> property_audio_output_type_;
        Glib::Property<int> property_color_balance_contrast_;
        Glib::Property<int> property_color_balance_saturation_;
        Glib::Property<int> property_color_balance_brightness_;
        Glib::Property<int> property_color_balance_hue_;
        Glib::Property<GstTagList*> property_our_audio_tags_;
        Glib::Property<GstTagList*> property_our_video_tags_;

        //Exposed signals
        sigc::signal<void(const char*, bool)> signal_error_;
        sigc::signal<void()> signal_eos_;
        sigc::signal<void(std::int64_t, std::int64_t, double, bool)> signal_tick_;
        sigc::signal<void()> signal_play_starting_;
        sigc::signal<void()> signal_got_metadata_;
        sigc::signal<void()> signal_btdemux_destructing_;
            
        //Internal used signal
        sigc::signal<void()> signal_audio_changed_;
        sigc::signal<void()> signal_video_changed_;

        sigc::connection              update_timer_;
        sigc::connection              eos_tag_;
        sigc::connection              realize_tag_;
};











/************************************************Extra Class init************************************************/
BaconVideoWidgetExtraInit::BaconVideoWidgetExtraInit()
    : ExtraClassInit(&BaconVideoWidgetExtraInit::class_init, nullptr, &BaconVideoWidgetExtraInit::instance_init)
{
}

void BaconVideoWidgetExtraInit::class_init(void* klass, void* /*user_data*/)
{

                               
    // printf("(BaconVideoWidgetExtraInit::class_init)\n");

    auto* const widget_klass = GTK_WIDGET_CLASS(klass);
    
    //must register, so we can add icon theme path
    g_resources_register(_bvw_get_resource());
    GtkIconTheme *default_theme = gtk_icon_theme_get_default();
    gtk_icon_theme_add_resource_path (default_theme, "/com/transmissionbt/transmission");
    
    gtk_widget_class_set_template_from_resource(widget_klass, gtr_get_full_resource_path("bacon-video-widget.ui").c_str());
    gtk_widget_class_bind_template_child_full (widget_klass, "stack", FALSE, 0);
    gtk_widget_class_bind_template_child_full (widget_klass,  "audio_only", FALSE, 0);
    gtk_widget_class_bind_template_child_full (widget_klass,  "broken_video", FALSE, 0);
}

void BaconVideoWidgetExtraInit::instance_init(GTypeInstance* instance, void* /*klass*/)
{
    // printf("(BaconVideoWidgetExtraInit::instance_init)\n");

    gtk_widget_init_template(GTK_WIDGET(instance));
}









/********************Static Functions for Gstreamer plugin signal callbacks**********************/
void BaconVideoWidget::Impl::on_pad_added_function(GstElement* decodebin, GstPad* pad, gpointer user_data)
{
  BaconVideoWidget::Impl* self = static_cast<BaconVideoWidget::Impl*>(user_data);
  if (self) self->on_pad_added_method(decodebin, pad);

}


void BaconVideoWidget::Impl::on_pad_removed_function(GstElement* decodebin, GstPad* pad, gpointer user_data)
{
  BaconVideoWidget::Impl* self = static_cast<BaconVideoWidget::Impl*>(user_data);
  if (self) self->on_pad_removed_method(decodebin, pad);

}


void BaconVideoWidget::Impl::on_btdemux_pad_added_function(GstElement *element, GstPad *pad, gpointer user_data)
{
  BaconVideoWidget::Impl* self = static_cast<BaconVideoWidget::Impl*>(user_data);
  if (self) self->on_btdemux_pad_added_method(element, pad);
}


void BaconVideoWidget::Impl::on_btdemux_pad_removed_function(GstElement *element, GstPad *pad, gpointer user_data)
{
  BaconVideoWidget::Impl* self = static_cast<BaconVideoWidget::Impl*>(user_data);
  if (self) self->on_btdemux_pad_removed_method(element, pad);
}



void BaconVideoWidget::Impl::on_btdemux_no_more_pads_function(GstElement *element, gpointer user_data)
{
  BaconVideoWidget::Impl* self = static_cast<BaconVideoWidget::Impl*>(user_data);
  if (self) self->on_btdemux_no_more_pads_method(element);
}





gboolean BaconVideoWidget::Impl::decodebin_audio_outpad_event_function(GstPad * pad, GstObject * parent, GstEvent * event)
{
  gpointer user_data = gst_pad_get_element_private(pad);
  BaconVideoWidget::Impl* self = static_cast<BaconVideoWidget::Impl*>(user_data);
  if (self) 
    self->decodebin_audio_outpad_event_method(event);

  return gst_pad_event_default (pad, parent, event);
}

void BaconVideoWidget::Impl::decodebin_audio_outpad_event_method(GstEvent * event)
{
  GstTagList *taglist;
  
          // printf("(bvw_decodebin_audio_outpad_event): %s \n", GST_EVENT_TYPE_NAME (event));

  if (GST_EVENT_TYPE (event) == GST_EVENT_TAG)
  {
      GstTagList *tags;
      //@taglist: (out) (optional) (transfer none):
      gst_event_parse_tag (event, &tags);
      if (tags)
      {

// if (GST_IS_TAG_LIST(tags))
//       printf("(yes taglist) \n");
//   else
//       printf("(not taglist) \n");

          //got audio tags means tags change from null to non-null, pass to tags-changed-related callbacks, even if tags actually not change for our torrent streaming
          update_tags(tags, StreamType::STREAM_TYPE_AUDIO);
      }
  }  
}




gboolean BaconVideoWidget::Impl::decodebin_video_outpad_event_function(GstPad * pad, GstObject * parent, GstEvent * event)
{
  gpointer user_data = gst_pad_get_element_private(pad);
  BaconVideoWidget::Impl* self = static_cast<BaconVideoWidget::Impl*>(user_data);
  if (self) 
    self->decodebin_video_outpad_event_method(event);

  return gst_pad_event_default (pad, parent, event);

}


void BaconVideoWidget::Impl::decodebin_video_outpad_event_method(GstEvent * event)
{
  GstTagList *taglist;
  
          // printf("(bvw_decodebin_video_outpad_event): %s \n", GST_EVENT_TYPE_NAME (event));

  if (GST_EVENT_TYPE (event) == GST_EVENT_TAG)
  {
      GstTagList *tags = NULL;
      tags = gst_tag_list_new_empty ();
      //@taglist: (out) (optional) (transfer none):
      gst_event_parse_tag (event, &tags);
      if (tags)
      {

// if (GST_IS_TAG_LIST(tags))
//       printf("(yes taglist) \n");
//   else
//       printf("(not taglist) \n");

          //got audio tags means tags change from null to non-null, pass to tags-changed-related callbacks, even if tags actually not change for our torrent streaming
          update_tags(tags, StreamType::STREAM_TYPE_VIDEO);
      }
  }

}









/********************************CTOR*********************************/

BaconVideoWidget::BaconVideoWidget()
    : Glib::ObjectBase(typeid(BaconVideoWidget))
{
  // printf("BaconVideoWidget::BaconVideoWidget()\n");
}






BaconVideoWidget::BaconVideoWidget(
    BaseObjectType* cast_item,
    Glib::RefPtr<Gtk::Builder> const& /*builder*/
)
    : Glib::ObjectBase(typeid(BaconVideoWidget))
    , Gtk::Bin(cast_item)
    , impl_(std::make_unique<Impl>(*this))
{

    set_can_focus(true);

    set_events(
        get_events() |
        Gdk::EventMask::SCROLL_MASK |
        Gdk::EventMask::POINTER_MOTION_MASK |
        Gdk::EventMask::BUTTON_MOTION_MASK |
        Gdk::EventMask::BUTTON_PRESS_MASK |
        Gdk::EventMask::BUTTON_RELEASE_MASK |
        Gdk::EventMask::KEY_PRESS_MASK
    );

}





// Constructor that loads its own .ui file using its own Gtk::Builder
BaconVideoWidget::Impl::Impl(BaconVideoWidget& widget) 
    :
    widget_(widget),
    stack_ (get_template_child<Gtk::Stack>("stack")),
    audio_only_ (get_template_child<Gtk::Image>("audio_only")),
    broken_video_ (get_template_child<Gtk::Image>("broken_video")),

    video_channels_(g_ptr_array_new ()),
    audio_channels_(g_ptr_array_new ()),
    btdemux_srcpads_(g_ptr_array_new()),

    property_seekable_(widget, "seekable", false),
    property_volume_(widget, "volume", -1.0),  
    property_audio_output_type_(widget, "audio-output-type", "stereo"),
    property_color_balance_contrast_(widget, "contrast", 32768),
    property_color_balance_saturation_(widget, "saturation", 32768),
    property_color_balance_brightness_(widget, "brightness", 32768),
    property_color_balance_hue_(widget, "hue", 32768),
    property_our_audio_tags_(widget, "audio-tags", nullptr),
    property_our_video_tags_(widget, "video-tags", nullptr)
{

  widget_.signal_realize().connect(sigc::mem_fun(*this, &BaconVideoWidget::Impl::on_realize_behavior));
  widget_.signal_unrealize().connect(sigc::mem_fun(*this, &BaconVideoWidget::Impl::on_unrealize_behavior));

  //for test
  // Glib::signal_timeout().connect_seconds(sigc::mem_fun(*this, &BaconVideoWidget::Impl::trigger_unrealize_behavior),10);



    // std::nullptr automatically converts to NULL when passed to C functions
    GError *temp_error = NULL;
    if(!gst_init_check(nullptr, nullptr, &temp_error))
    {
        gst_init_errors_ = Glib::Error(temp_error);
        
        std::cerr << "Gstreamer library initialization failed " << gst_init_errors_.what() << std::endl;
    }
    //used for generating missing plugin 
    gst_pb_utils_init ();
 

    // In C++, a const char* can safely hold a const gchar*, since there's no type mismatch
    gchar* gst_version_str = gst_version_string ();
    std::cout << "Bacon's Gstreamer version: " << gst_version_str << std::endl;
    g_free (gst_version_str);






    // Create the pipeline element
    pipeline_ = gst_pipeline_new("bvw-pipeline");

    // torrent "demuxer", push torrent piece to decodebin. a bit like filesrc
    btdemux_ = element_make_or_warn("btdemux", "btdemux");
    
    // a high-level element used for demuxing and deocding, such as qtdemux, decoders , etc...
    decodebin_ = element_make_or_warn("decodebin", "decodebin");
    
    //serves as a container for OpenGL-based rendering, providing a bridge between multimedia streaming and graphics rendering.
    glsinkbin_ = element_make_or_warn("glsinkbin", "glsinkbin");

    // render video using OpenGL within a GTK application, taking advantage of OpenGL for enhanced visual effects
    video_sink_ = element_make_or_warn("gtkglsink", "video-sink");

    //adjusts the playback rate of a media stream
    audio_pitchcontrol_ = element_make_or_warn("scaletempo", "scaletempo");
    
    volume_plugin_ = element_make_or_warn("volume", "volume");
    
    audio_sink_ = element_make_or_warn("autoaudiosink", "audio-sink");



    //********** Errors Cleaning up for partially constructed pipeline
    if(!pipeline_ ||
      !btdemux_ ||
      !decodebin_ ||
      !audio_pitchcontrol_ ||
      !video_sink_ ||
      !glsinkbin_ ||
      !volume_plugin_ ||
      !audio_sink_) 
    {
        // In GStreamer, newly created elements usually start with floating refs
        // g_object_ref_sink() ensures the object is in a state where g_clear_object() can properly release it.
        if (video_sink_)
            g_object_ref_sink (video_sink_);
        g_clear_object (&video_sink_);
        if (audio_sink_)
            g_object_ref_sink (audio_sink_);
        g_clear_object (&audio_sink_);
        if (glsinkbin_)
            g_object_ref_sink (glsinkbin_);
        g_clear_object (&glsinkbin_);
        if (volume_plugin_)
          g_object_ref_sink (volume_plugin_);
        g_clear_object (&volume_plugin_);
        init_error_ = Glib::Error(
            BVW_ERROR,
            static_cast<int>(BVW_ERROR_PLUGIN_LOAD),
            "Some necessary plug-ins are missing. "
            "Make sure that the program is correctly installed.");  
        return;
    }


//Maybe No Need GST_LOG
#ifndef GST_DISABLE_GST_DEBUG
//register GST debugging category
    if (_trtotem_gst_debug_cat == NULL) 
    {
      GST_DEBUG_CATEGORY_INIT (_trtotem_gst_debug_cat, "trtotem", 0,
          "Transmission trTotem GStreamer Backend");
    }
#endif


      
    g_mutex_init(&seek_mutex_);
    clock_ = gst_system_clock_obtain();




              /*******  Create video output widget ********/
/*
                _______________________glsinkbin________________________
                |          gtkglsink                                    |
                |_______________________________________________________|
*/
              /*video-sink*/
              // control the display of frames per second (FPS) statistics  ,used for performance monitoring
              if (is_feature_enabled ("FPS_DISPLAY")) {
                GstElement *fps;
                fps = gst_element_factory_make ("fpsdisplaysink", "fpsdisplaysink");
                g_object_set (glsinkbin_, "sink", fps, NULL);
                g_object_set (fps, "video-sink", video_sink_, NULL);
              } 
              else 
              {
                g_object_set (glsinkbin_, "sink", video_sink_, NULL);
              }
              
              GtkWidget* video_widget_c = nullptr;  // Raw GtkWidget pointer
              // Get the underlying GtkWidget* from the "widget" property of GstGtkGLSink
              g_object_get(video_sink_, "widget", &video_widget_c, NULL);

              if (video_widget_c) {
                // Wrap the raw GtkWidget* into a Gtk::Widget*, so we no need to free video_widget_c after this Glib::wrap 
                video_widget_ = Glib::wrap(video_widget_c);
                video_widget_->show();
                // Add the video widget to the stack and set it as the visible child
                stack_->add(*video_widget_, "video");
                stack_->set_visible_child("video");
                // Gtkmm will manage the widget, so no need to unref it manually
              }
              
              //how to interpret the orientation of video frames control how the video is oriented and displayed.
              //eg. Horizontal :where the width of the video is greater than its height.
              //    Vertical :where the height is greater than the width
              g_object_set (video_sink_,
                            "rotate-method", GST_VIDEO_ORIENTATION_AUTO,
                            NULL);

              //store as field for getting tags event
              video_sinpad_decodebin_ = gst_element_get_static_pad (glsinkbin_, "sink");
   

/* Audio Processing Chain 

                       -------------------[audiosinkbin] ------------------------------------------------------------------------------
                       |                                                                                                              |
     (ghost pad)       |        (sink)[audioconvert](src)  (sink)[capsfilter] (src) ---- (sink)[scaletempo](src) ---- (sink)[autoaudiosink](src)          |  (src)
              |        ---------------|--------------------------------------------------------------------------------|------------  |
              |_______________________|                                                                                |______________|


*/
              /* Link the audiopitch element */
              // filter the capabilities (caps) of the media data being processed in a pipeline
              audio_capsfilter_ = gst_element_factory_make("capsfilter", "audiofilter");

              audio_filter_convert_ = gst_element_factory_make("audioconvert", "audioconvert");


              // Container that can hold other GStreamer elements
              audio_bin_ = gst_bin_new ("audiosinkbin");
              //used to add multiple GstElement instances to a GstBin
              gst_bin_add_many (GST_BIN (audio_bin_),
                                audio_filter_convert_,
                                audio_capsfilter_,
                                audio_pitchcontrol_,
                                volume_plugin_,
                                audio_sink_, 
                                NULL);


              //link multiple GstElement instances together in sequence
              //connecting the output pad of one element to the input pad of the next
              gst_element_link_many (audio_filter_convert_,
                                     audio_capsfilter_,
                                     audio_pitchcontrol_,
                                     volume_plugin_,
                                     audio_sink_,
                                     NULL);

               
              // GstBin does not inherently have a "sink" or "src" pad because it's a container for other elements
              // it uses ghost pads to expose pads from the elements inside it to the outside world
              // created a ghost pad for audio_bin that points to the "sink" pad of audio_capsfilte
              // Ghost pads are used to make the pads of internal elements accessible from the outside
              GstPad *audio_convert_pad;
              audio_convert_pad = gst_element_get_static_pad (audio_filter_convert_, "sink");
            
              
                      // GstCaps *pad_caps;
                      // gchar *caps_str;
                      // pad_caps = gst_pad_query_caps(audio_convert_pad, NULL);
                      // Optionally, print the capabilities to debug
                      // caps_str = gst_caps_to_string(pad_caps);
                      // printf(" audio_convert sink pad capabilities: %s\n", caps_str);
                      // g_free(caps_str);
               

              // audio_bin_ now has a "sink" ghost pad that maps to the "sink" pad of audio_capsfilter
              gst_element_add_pad (audio_bin_, gst_ghost_pad_new ("sink", audio_convert_pad));
              gst_object_unref (audio_convert_pad);

              //store as field for getting tags event
              audio_sinpad_decodebin_ = gst_element_get_static_pad (audio_bin_, "sink");


                      // GstPad* audio_bin_sinkpad = gst_element_get_static_pad (audio_bin_, "sink");
                      // GstCaps *audio_bin_sinkpad_caps;
                      // gchar *audio_bin_sinkpad_caps_str;
                      // audio_bin_sinkpad_caps = gst_pad_query_caps(audio_bin_sinkpad, NULL);
                      // // Optionally, print the capabilities to debug
                      // audio_bin_sinkpad_caps_str = gst_caps_to_string(audio_bin_sinkpad_caps);
                      // printf(" audio_bin sink pad capabilities: %s\n", audio_bin_sinkpad_caps_str);
                      // g_free(audio_bin_sinkpad_caps_str);
           

              /* Now, Construct the Pipeline */
              // Adds a %NULL-terminated list of elements to a bin
              gst_bin_add_many (GST_BIN(pipeline_), btdemux_, decodebin_, glsinkbin_, audio_bin_, NULL);

   
              // First link btdemux -> decodebin thru 'on_btdemux_pad_added' callback (dynamically), once got src pad of btdemux, link it to decodebin
              g_signal_connect(btdemux_, "pad-added", G_CALLBACK(BaconVideoWidget::Impl::on_btdemux_pad_added_function), this);

              //switch item in playlist ,remove old btmux pad
              g_signal_connect(btdemux_, "pad-removed", G_CALLBACK(BaconVideoWidget::Impl::on_btdemux_pad_removed_function), this);

              g_signal_connect(btdemux_, "no-more-pads", G_CALLBACK(BaconVideoWidget::Impl::on_btdemux_no_more_pads_function), this);

              // link the video pad from decodebin to the video sink (inside glsinkbin_)
              // also link the audio pad from decodebin to the audio sink (inside audio_bin_)
              g_signal_connect(decodebin_, "pad-added", G_CALLBACK(BaconVideoWidget::Impl::on_pad_added_function), this);
 
              //Also add pad-removed cb 
              g_signal_connect(decodebin_, "pad-removed", G_CALLBACK(BaconVideoWidget::Impl::on_pad_removed_function), this);
            

              /* pipeline bus managemenet */
              // Retrieve the bus from the pipeline and store it in the BaconVideoWidget struct
              // only a GstPipeline will provide a bus for the application.
              bus_ = gst_element_get_bus(pipeline_);
  
              gst_bus_add_signal_watch (bus_);

              sig_bus_async_ = g_signal_connect (bus_, "message", 
                    G_CALLBACK (BaconVideoWidget::Impl::bus_message_cb_function), this);



    //******Our own signals******       
    signal_video_changed_.connect(sigc::mem_fun(*this, &BaconVideoWidget::Impl::update_stream_info));
    signal_audio_changed_.connect(sigc::mem_fun(*this, &BaconVideoWidget::Impl::update_stream_info));


    //No need listen for audio/video-tags-changed

    //we want to receive notification when a property's value changes, by connecting to signal_changed()
    property_color_balance_contrast_.get_proxy().signal_changed().connect(sigc::mem_fun(*this, &BaconVideoWidget::Impl::set_color_balance_contrast));
    property_color_balance_saturation_.get_proxy().signal_changed().connect(sigc::mem_fun(*this, &BaconVideoWidget::Impl::set_color_balance_saturation));
    property_color_balance_brightness_.get_proxy().signal_changed().connect(sigc::mem_fun(*this, &BaconVideoWidget::Impl::set_color_balance_brightness));
    property_color_balance_hue_.get_proxy().signal_changed().connect(sigc::mem_fun(*this, &BaconVideoWidget::Impl::set_color_balance_hue));
    property_audio_output_type_.get_proxy().signal_changed().connect(sigc::mem_fun(*this, &BaconVideoWidget::Impl::on_audio_output_type_changed));
    
    //loading volume, default volue is 100% every time open
    volume_readback();
}


BaconVideoWidget::~BaconVideoWidget() 
{
    std::cout << "BaconVideoWidget::~BaconVideoWidget() " << std::endl;

}





BaconVideoWidget::Impl::~Impl()
{
    std::cout << "BaconVideoWidget::Impl::~Impl()" << std::endl;

    //let Session know btdemux is goona destruct, so dont call functions exposed by btdemux
    // signal_btdemux_destructing_.emit();
    
    /*Clear Gstreamer Bus*/
    if(bus_) 
    {
      /* make bus drop all messages to make sure none of our callbacks is ever
       * called again (main loop might be run again to display error dialog) */
      gst_bus_set_flushing (bus_, TRUE);  
      if(sig_bus_async_)
        g_signal_handler_disconnect (bus_, sig_bus_async_);
      g_clear_pointer (&bus_, gst_object_unref);
    }
    g_clear_object (&clock_);

    /*Clear Gstreamer Pipeline (elements)*/
    bvw_gstreamer_pipeline_cleanup();

    if(update_timer_.connected())
    {
      update_timer_.disconnect();
    }
    if(eos_tag_.connected())
    {
      eos_tag_.disconnect();
    }

    if(tagcache_ != nullptr)
      g_clear_pointer (&tagcache_,  gst_tag_list_unref);

    GstTagList* temp_taglist = property_our_audio_tags_.get_value();
    if(temp_taglist)
    {
      gst_tag_list_unref(temp_taglist);
      property_our_audio_tags_.set_value(NULL);
    }

    temp_taglist = property_our_video_tags_.get_value();
    if(temp_taglist)
    {
      gst_tag_list_unref(temp_taglist);
      property_our_video_tags_.set_value(NULL);
    }
    temp_taglist = NULL;

    //clear video_channels
    for (guint i = 0; i < video_channels_->len; i++) {
      GstPad *pad = static_cast<GstPad*>(g_ptr_array_index(video_channels_, i));
      gst_object_unref (pad);  // Decrement reference count
    }
    g_ptr_array_free (video_channels_, TRUE);


    //clear audio_channels
    for (guint i = 0; i < audio_channels_->len; i++) {
      GstPad *pad = static_cast<GstPad*>(g_ptr_array_index(audio_channels_, i));
      gst_object_unref (pad);  // Decrement reference count
    }
    g_ptr_array_free (audio_channels_, TRUE);


    //clear btdemux_srcpads
    for(guint i = 0; i < btdemux_srcpads_->len; i++) {
      GstPad *pad = static_cast<GstPad*>(g_ptr_array_index(btdemux_srcpads_, i));
      gst_object_unref (pad);  // Decrement reference count
    }
    g_ptr_array_free (btdemux_srcpads_, TRUE);


    //unref decodebin input(sink) pad for audio port
    if(audio_sinpad_decodebin_)
    {
      gst_object_unref (audio_sinpad_decodebin_);
    }
    //unref decodebin input(sink) pad for video port
    if(video_sinpad_decodebin_)
    {
      gst_object_unref (video_sinpad_decodebin_);
    }

    //clear seek mutex
    g_mutex_clear(&seek_mutex_);

}

void BaconVideoWidget::Impl::bvw_gstreamer_pipeline_cleanup()
{
  // if(btdemux_)
  // {
  //   gst_object_unref(btdemux_);
  // }
  // if(decodebin_)
  // {
  //   gst_object_unref(decodebin_);
  // }
  // if(audio_bin_)
  // {
  // gst_object_unref(audio_bin_);
  // }
  /*
  (transmission-gtk:27464): GStreamer-CRITICAL **: 11:23:23.021: 
Trying to dispose object "glsinkbin", but it still has a parent "bvw-pipeline".
You need to let the parent manage the object instead of unreffing the object directly.

So, Just unref the pipeline is enough ?? no need to manually unref those element within ???
  */
  // if(glsinkbin_)
  // {
  // gst_object_unref(glsinkbin_);
  // }
  // if(video_sink_)
  // {
  // gst_object_unref(video_sink_);
  // }
  // if(audio_filter_convert_)
  // {
  // gst_object_unref(audio_filter_convert_);
  // }
  // if(audio_capsfilter_)
  // {
  //   gst_object_unref(audio_capsfilter_);
  // }
  // if(audio_pitchcontrol_)
  // {
  //   gst_object_unref(audio_pitchcontrol_);
  // }
  // if(volume_plugin_)
  // {
  //   gst_object_unref(volume_plugin_);
  // }
  // if(audio_sink_)
  // {
  //   gst_object_unref(audio_sink_);
  // }
  if (pipeline_)
  {
    printf ("(bacon_video_widget_finalize) SET pipeline_ state to NULL\n");
    gst_element_set_state (pipeline_, GST_STATE_NULL);
    g_clear_object (&pipeline_);
  }
    
}





/********************************************Internally Used Methods**********************************************/
template<typename T>
T* BaconVideoWidget::Impl::get_template_child(char const* name) const
{

    auto full_type_name = std::string("gtkmm__CustomObject_");
    Glib::append_canonical_typename(full_type_name, typeid(BaconVideoWidget).name());

    return Glib::wrap(G_TYPE_CHECK_INSTANCE_CAST(
        gtk_widget_get_template_child(GTK_WIDGET(widget_.gobj()), g_type_from_name(full_type_name.c_str()), name),
        T::get_base_type(),
        typename T::BaseObjectType));
}



void BaconVideoWidget::Impl::update_cursor()
{
    // bool is_active = parent_toplevel_->is_active();
    // printf ("(update_cursor) %s\n", is_active ? "ACTIVE" : "NOT-ACTIVE");

    // Get the Gdk::Window associated with BaconVideoWidget
    Glib::RefPtr<Gdk::Window> window = widget_.get_window();

    /*Case 1: When Focus Lost, Mouse hovering over BaconVideoWidget*/
    // if BaconVideoWidget is not on focus, such as you press another application's window area, So when you then hovering on the focus-lost BaconVideoWidget, no cursor shown,
    // only when you mouse press the BaconVideoWidget area, which let it gain focus, cursor will show again
    if(parent_toplevel_ && !parent_toplevel_->is_active()){
      
      auto display = Gdk::Display::get_default();
      auto cursor = Gdk::Cursor::create(display, Gdk::CursorType::BLANK_CURSOR);
      window->set_cursor(cursor); 
      return;
    }

    /*Case 2: When Focus Held, Mouse hovering over BaconVideoWidget*/
    //show cursor, cooperate with TotemWindow::Impl::set_controls_visibility() , so when mouse motion over BaconVideoWidget, cursor will be shown,
    //but if mouse still a few seconds later, cursor will be hidden 
    if(cursor_shown_){        
        window->set_cursor();  
    }
    //show blank curosr (equivalent as hide the curosr)
    else{
      auto display = Gdk::Display::get_default();
      auto cursor = Gdk::Cursor::create(display, Gdk::CursorType::BLANK_CURSOR);
      window->set_cursor(cursor);
    }
}




void BaconVideoWidget::Impl::set_current_actor()
{
    Glib::ustring page;  // Use Glib::ustring instead of std::string

    if (media_has_audio_ && !media_has_video_) {
        page = "audio-only";
    }
    else if (media_has_unsupported_video_) {
        page = "broken-video";
    }
    else {
        page = "video";
    }

    // Set the visible child in the Gtk::Stack
    stack_->set_visible_child(page);  // Pass Glib::ustring to set_visible_child()
}





//NOTE: gets called just after realize() method has been called
void BaconVideoWidget::Impl::on_realize_behavior()
{
  std::cout << "void BaconVideoWidget::Impl::on_realize_behavior() " <<std::endl;

  // Get the parent toplevel window (Gtk::Window)
  parent_toplevel_ = dynamic_cast<Gtk::Window*>(widget_.get_toplevel());
  if (parent_toplevel_) {
      // Connect to the "is-active" property's signal_changed() signal
      realize_tag_ = parent_toplevel_->property_is_active().signal_changed().connect(
          sigc::mem_fun(*this, &BaconVideoWidget::Impl::update_cursor)
      );
  }
}


//NOTE: gets called just after unrealize() method has been called (implicitly calling unrealize() when close Totem's Window)

void BaconVideoWidget::Impl::on_unrealize_behavior()
{
  std::cout << "void BaconVideoWidget::Impl::on_unrealize_behavior() " <<std::endl;

  // Cleanup: disconnect the signal handler for the "is-active" property
  if (parent_toplevel_) {
    if(realize_tag_.connected())
      realize_tag_.disconnect();
    parent_toplevel_ = nullptr;
  }
}

//just for test, trigger a signal unrealize to be activated 
bool BaconVideoWidget::Impl::trigger_unrealize_behavior()
{
  std::cout << "bool BaconVideoWidget::Impl::trigger_unrealize_behavior() " <<std::endl;
  
  // Unrealize will Cause a widget to be unrealized (frees all GDK resources associated with the widget
  widget_.unrealize();
  return false;
}



//*************************GStreamer related*****************************
gboolean BaconVideoWidget::Impl::is_feature_enabled (const char *env)
{
  const char *value;

  g_return_val_if_fail (env != NULL, FALSE);
  value = g_getenv (env);
  return g_strcmp0 (value, "1") == 0;
}

GstElement* BaconVideoWidget::Impl::element_make_or_warn (const char *plugin, const char *name)
{
  GstElement *element;
  element = gst_element_factory_make (plugin, name);
  if (!element){
      std::cerr << "Element '" << plugin << "' is missing, verify your installation" << std::endl;
  }

  return element;
}


// docodebin -- audio,video output
// dynamically check the type of the pad from decodebin (whether it's video or audio) 
// and connect it to the appropriate sink elements
//NOTE:when moov after mdat,qtdemux will initiate a seek, after btdemux push the piece contaning moov and reset 
//pushing from first piece, after these done, can gstdecodebin2 srcpad added, so on_pad_added below will be called
void BaconVideoWidget::Impl::on_pad_added_method(GstElement* decodebin, GstPad* pad)
{
  GstPad *sink_pad = NULL;
  GstCaps *pad_caps;
  GstStructure *structure;
  const gchar *media_type;

  const gchar *pad_name = GST_PAD_NAME (pad);
  printf("(bvw/on_pad_added for decodebin) :%s\n", pad_name);

  pad_caps = gst_pad_query_caps (pad, NULL);

          // guint caps_sz =  gst_caps_get_size (pad_caps);
          // printf ("(decodebin2/on_pad_added) caps size is %d \n", caps_sz);

                    // Optionally, print the capabilities to debug
                    // gchar *caps_str;
                    // caps_str = gst_caps_to_string(pad_caps);
                    // printf("Pad capabilities: %s\n", caps_str);
                    // g_free(caps_str);

  // Extract the structure from the first (top-level) capability
  structure = gst_caps_get_structure (pad_caps, 0);
  media_type = gst_structure_get_name (structure);  // Get the media type (e.g., "audio/x-raw" or "video/x-raw")

  /****************AUDIO********************** */
  if (g_str_has_prefix (media_type, "audio/x-raw")) 
  {

    gst_pad_set_element_private(pad, (gpointer)(char*)"audio");  // Store as audio

    g_print("decodebin's Audio pad detected.\n");

    // Get the audio sink pad and link it
    sink_pad = audio_sinpad_decodebin_;
    if (!sink_pad) 
    {
        g_warning("Failed to get the ghost 'sink' pad from audio_bin");
        goto beach;
    }
    if (sink_pad && !gst_pad_is_linked(sink_pad)) 
    {
                  // GstCaps *pad_caps_after_set;
                  // gchar *caps_str_after_set;
                  // pad_caps_after_set = gst_pad_query_caps(sink_pad, NULL);
                  // // Optionally, print the capabilities to debug
                  // caps_str_after_set = gst_caps_to_string(pad_caps_after_set);
                  // printf(" audio_bin sink pad caps: %s\n", caps_str_after_set);
                  // g_free(caps_str_after_set);

        GstPadLinkReturn link_result = gst_pad_link (pad, sink_pad);

                  // printf("(on_pad_added) gst_pad_link ret:%d \n", (int)link_result);

        if (link_result != GST_PAD_LINK_OK) 
        {
            g_warning("Failed to link audio pad to audio sink");
            goto beach;
        }

        // Store `this` as private data on the pad
        gst_pad_set_element_private(audio_sinpad_decodebin_, this);

        //for get tags event
        gst_pad_set_event_function_full (audio_sinpad_decodebin_,
          static_cast<GstPadEventFunction>(BaconVideoWidget::Impl::decodebin_audio_outpad_event_function), NULL, NULL);
    }


    //***cache the decodebiin's audio ouutput pad for later use
    g_ptr_array_add(audio_channels_, gst_object_ref (pad));


    //***when decodebin output pad added(such as when start playing or switch to next in playlist), we emit a audio-changed signal on bvw
    // g_signal_emit (bvw, bvw_signals[SIGNAL_AUDIO_CHANGED], 0, NULL);
    signal_audio_changed_.emit();

  }
  /****************VIDEO********************/
  else if (g_str_has_prefix(media_type, "video/x-raw")) 
  {
      gst_pad_set_element_private(pad, (gpointer)(char*)"video");  // Store as video

      g_print("decodebin's Video pad detected.\n");
      // Get the video sink pad and link it
      sink_pad = video_sinpad_decodebin_;
      if (!sink_pad) 
      {
          g_warning("Failed to get 'sink' pad of glsinkbin_");
          goto beach;
      }

      if (sink_pad && !gst_pad_is_linked(sink_pad)) 
      {
          if (gst_pad_link(pad, sink_pad) != GST_PAD_LINK_OK) 
          {
              g_warning("Failed to link video pad to video sink");
              goto beach;
          }

          // Store `this` as private data on the pad
          gst_pad_set_element_private(video_sinpad_decodebin_, this);

          //for get tags event
          gst_pad_set_event_function_full (video_sinpad_decodebin_,
            static_cast<GstPadEventFunction>(BaconVideoWidget::Impl::decodebin_video_outpad_event_function), NULL, NULL);
      }

      //***cache the decodebiin's video output pad for later use
      g_ptr_array_add (video_channels_, gst_object_ref (pad));


      //***when decodebin output pad added(such as when start playing or switch to next in playlist), we emit a video-changed signal on bvw
      // g_signal_emit (bvw, bvw_signals[SIGNAL_VIDEO_CHANGED], 0, NULL);
      signal_video_changed_.emit();

  }

  beach:
    gst_caps_unref (pad_caps);  // Unref the capabilities object

}


void BaconVideoWidget::Impl::on_pad_removed_method(GstElement* decodebin, GstPad* pad)
{
  if (!GST_IS_PAD (pad))
  {
    printf ("(bvw/on_pad_removed) not pad, return \n");
    return;
  }

  //the pad that link to gstdeocdebin2's output pad (eg. src_0, src_1)
  GstPad *sink_pad = NULL;

  GstStructure *structure;
  const gchar *media_type;


  //caps is empty ,cant use it to distinguish audio or video
  const gchar *pad_type = static_cast<const gchar*>(gst_pad_get_element_private(pad));  // Retrieve stored type

  const gchar *pad_name = GST_PAD_NAME (pad);
      printf("(bvw/on_pad_removed for decodebin) :%s, pad_type is %s\n", pad_name, pad_type);

  if (g_strcmp0 (pad_type, "audio") == 0) 
  { 
      guint x=0;
      if (g_ptr_array_find (audio_channels_, pad, &x))
      {
        printf ("(bvw/on_pad_removed) existed in audio channels at %d\n", x);
        
        //unlinking pad 
        sink_pad = audio_sinpad_decodebin_;
        if (!sink_pad) {
            g_warning("Failed to get the ghost 'sink' pad from audio_bin");
            goto beach;
        }

        if (sink_pad && gst_pad_is_linked (audio_sinpad_decodebin_)) 
        {
          if (gst_pad_unlink (pad, sink_pad)){
              printf ("(bvw/on_pad_removed for decodebin) unlink audio srcpad with audio_bin success \n");
          } else {
              printf ("(bvw/on_pad_removed for decodebin) unlink audio srcpad with audio_bin failed \n");
          }
        }
        else
        {
          printf ("(bvw/on_pad_removed for decodebin) audio_bin sinkpad is not linked with any pad, no need to unlink \n");
        }

        GstPad* to_remove = static_cast<GstPad*>(g_ptr_array_index(audio_channels_, x));
        if(to_remove)
        {
          gst_object_unref(to_remove);
        }
        if (g_ptr_array_remove (audio_channels_, pad)){
          printf ("Removed decodebin's Audio pad from audio_channels, len after remove is %d\n",audio_channels_->len);
        }else{
          printf ("Failed Removing decodebin's Audio pad from audio_channels\n");
        }
  
      }
  }
  else if (g_strcmp0 (pad_type, "video") == 0) 
  {
    guint x=0;
    if (g_ptr_array_find (video_channels_, pad, &x))
    {
      printf ("(bvw/on_pad_removed) existed in video channels at %d\n", x);
    
      //unlinking pad
      sink_pad = video_sinpad_decodebin_;
      if (!sink_pad) {
          g_warning("Failed to get 'sink' pad of glsinkbin_");
          goto beach;
      }

      if (sink_pad && gst_pad_is_linked (video_sinpad_decodebin_)) 
      {
          if (gst_pad_unlink (pad, sink_pad)){
              printf ("(bvw/on_pad_removed for decodebin) unlink video srcpad with glsinkbin success \n");
          }
          else{
              printf ("(bvw/on_pad_removed for decodebin) unlink video srcpad with glsinkbin failed \n");
          }
      }
      else
      {
          printf ("(bvw/on_pad_removed for decodebin)  glsinkbin sinkpad is not linked with any pad, no need to unlink \n");
      }

      GstPad* to_remove = static_cast<GstPad*>(g_ptr_array_index(video_channels_, x));

      if(to_remove)
      {
        gst_object_unref(to_remove);
      }
      if(g_ptr_array_remove (video_channels_, pad)){
        printf ("Removed decodebin's Video pad from video_channels, len after remove is %d\n",video_channels_->len);
      }else{
        printf ("Failed Removing decodebin's Video pad from video_channels\n");
      }

    }
  }
  else
  {
    printf ("(bvw/on_pad_removed for decodebin) %s not found \n", pad_type);
    goto beach;
  }

  // printf ("(on_pad_removed for decodebin) END \n");

  beach:
  ;

}



//Callback once `gst_element_add_pad` called 
// Callback function for pad-added signal from btdemux (to handle dynamic src pad)
// dont send stream-start event once you got an srcpadd on btdemux added, totem-playlsit choose the desired fileidx,
// the undesired pads will be removed, afther that, it is the final one we really to link to decodebin and plays it
void BaconVideoWidget::Impl::on_btdemux_pad_added_method(GstElement* element, GstPad* pad)
{
     // Get the name of the pad and check if it's a source pad (the ones we're interested in)
     const gchar *pad_name = GST_PAD_NAME (pad);
     g_print("(on_btdemux_pad_added) btdemux src pad added: %s\n", pad_name);
 
     if (g_str_has_prefix(pad_name, "src_")) 
     {
         // This is a source pad, so we need to link it to decodebin
         GstPad *decodebin_sink_pad = gst_element_get_static_pad (decodebin_, "sink");
 
           //only link when we already set fileidx desired
          if (cur_video_fileidx_within_tor_ != -1)
          {
             //before linking, check whether there are existing link ,if any, unlink it
             if (gst_pad_is_linked (decodebin_sink_pad)
                 && btdemux_srcpads_->len > 0)
             {
               printf ("(on_btdemux_pad_added) Existing link between btdemux and decodebin2 checked, try to unlink \n");
 
               GstPad* old_pad = static_cast<GstPad*>(g_ptr_array_index(btdemux_srcpads_, 0));
               if (old_pad && !gst_pad_unlink (old_pad, decodebin_sink_pad))
               {
                   printf ("(on_btdemux_pad_added) unlink the old links failed \n");
               }
             }
 
             //and then link the new pad to gstdecodebin2
             GstPadLinkReturn ret = gst_pad_link (pad, decodebin_sink_pad);
 
                           // int is_flushing = (int) GST_PAD_IS_FLUSHING (decodebin_sink_pad);
                           // printf ("(on_btdemux_pad_added) the decodebin_sink_pad is_flushing:%d \n", is_flushing);
 
             if (ret != GST_PAD_LINK_OK) 
             {
                 printf ("(on_btdemux_pad_added) Failed to link btdemux src pad (%s) to decodebin sink pad, ret(%d)\n", pad_name, (int)ret);
             } 
             else 
             {
                 printf ("(on_btdemux_pad_added) Successfully linked btdemux src pad (%s) to decodebin sink pad \n", pad_name);
 
                 //store it , we will use it later, access still by fileidx (0,1,2,3...)
                 g_ptr_array_add (btdemux_srcpads_, gst_object_ref (pad));
 
                 //if it is our desired srcpad of btdemux, then send stream-start event
             
                 // dont forget to free it after use
                 gchar *desired_pad_name = g_strdup_printf ("src_%02d", cur_video_fileidx_within_tor_) ;
 
                 //check if the added pad's name match our desired_pad_name, (such as src_00. src_01...) if it is ,send stream-start event
                 if (g_strcmp0(pad_name, desired_pad_name) == 0) {
 
                   // printf ("(on_btdemux_pad_added) GST_PAD_MODE (pad) is %d \n",(int)GST_PAD_MODE (pad));
                   printf ("(on_btdemux_pad_added) gst_pad_is_active (pad) is %d \n",(int)gst_pad_is_active (pad));
 
                   //if the pad previously added and removed ,and here we add it again, gst_pad_is_active may fail before gst_element_add_pad called 
                   //activate it again
                   if( !gst_pad_is_active (pad) ){
                     if( !gst_pad_set_active (pad, TRUE) ){
                         printf ("(on_btdemux_pad_added) ENABLE gst_pad_set_active failed \n");
                     }else{  
                         printf ("(on_btdemux_pad_added) ENABLE gst_pad_set_active ok \n");
                     }
                   }
 
                   gchar *stream_id;
                   stream_id =
                       gst_pad_create_stream_id_printf (pad, btdemux_,
                       "%02x", stream_id_seq_);
 
                     // printf ("(on_btdemux_pad_added) Stream-start event has stream id %s on pad '%s'\n", stream_id, pad_name);
             
                   GstEvent *stream_start_event = gst_event_new_stream_start (stream_id);
                   if ( !gst_pad_push_event (pad, stream_start_event) ) 
                   {
                     //failed cuz the pad is flushing
                     g_warning ("(on_btdemux_pad_added) Failed to push stream-start event on pad '%s'", pad_name);
                   } 
                   else 
                   {
                       stream_id_seq_++;
                       printf ("(on_btdemux_pad_added) Stream-start event pushed on pad '%s'\n", pad_name);
                   }
 
                               // // g_object_set (dec_elem, "sink-caps", caps, NULL);
                               // gboolean caps_set = gst_pad_has_current_caps (pad);
                               // if (caps_set) {
                               //   GstCaps* format = gst_pad_get_current_caps (pad);
                               //   if (format) {
                               //     gchar* capstr = gst_caps_to_string (format);
                               //     printf ("(on_btdemux_pad_added) Got caps set on pad is %s",capstr);
                               //     g_free (capstr);
                               //     gst_object_unref (format);
                               //   } else {
                               //     printf ("(on_btdemux_pad_added) Failed Got caps set on pad\n");
                               //   }
                               // }else{
                               //     printf ("(on_btdemux_pad_added) No caps set on pad\n");
                               // }
                 }
 
                 g_free (desired_pad_name);
             }
          }   
         gst_object_unref (decodebin_sink_pad);
     }
}



void BaconVideoWidget::Impl::on_btdemux_pad_removed_method(GstElement* element, GstPad* pad)
{
  const gchar *pad_name = GST_PAD_NAME(pad);
    
  printf ("(on_btdemux_pad_removed) btdemux src pad removed: %s\n", pad_name);

  //unlink if it has been linked to the pad that will be removed
  if ( gst_pad_is_linked (pad) )
  {
    GstPad *decodebin_sink_pad = gst_element_get_static_pad (decodebin_, "sink");

    if (gst_pad_unlink (pad, decodebin_sink_pad))
    {
         printf ("(on_btdemux_pad_removed) unlink success %s\n", pad_name);

    }
    else{
         printf ("(on_btdemux_pad_removed) unlink failed %s\n", pad_name);

    }

    gst_object_unref (decodebin_sink_pad);
  }

  if (btdemux_srcpads_->len)
  {
    guint x=0;
    if (g_ptr_array_find(btdemux_srcpads_, pad, &x))
    {
        if (g_ptr_array_remove_index (btdemux_srcpads_, x) != NULL)
        {
            printf ("(on_btdemux_pad_removed) btdemux src pad removed successfully: %s\n", pad_name);
        }
        else
        {
            printf ("(on_btdemux_pad_removed) btdemux src pad removed failed Not Found %s\n", pad_name);
        }
    }   
  }
}



void BaconVideoWidget::Impl::on_btdemux_no_more_pads_method(GstElement* element)
{

  //btdemux_srcpads_ are expected to only have one or zero element
  if (btdemux_srcpads_->len == 1)
  {
      GstPad *pad = static_cast<GstPad*>(g_ptr_array_index(btdemux_srcpads_, 0));
      if(pad == NULL)
      {
        printf ("(on_btdemux_no_more_pads) on no more pads: Not found\n");
        return;
      }

      const gchar *pad_name = GST_PAD_NAME(pad);
  
      printf ("(on_btdemux_no_more_pads) on no more pads: %s\n", pad_name);

      // GstEvent *stream_start_event = gst_event_new_stream_start ("totem");
      // if (!gst_pad_push_event (pad, stream_start_event)) 
      // {
      //     g_warning ("Failed to push stream-start event on pad '%s'", pad_name);
      // } 
      // else 
      // {
      //     g_print ("(on_btdemux_no_more_pads) Stream-start event pushed on pad '%s'\n", pad_name);
      // }
  }
  else
  {
      printf ("(on_btdemux_no_more_pads) Not Found btdemux src pad stored in btdemux_srcpads_ \n");
  }
}





/*************************Missing Plugins GErrors**********************/
namespace{
typedef gchar * (* MsgToStrFunc) (GstMessage * msg);

gchar ** bvw_get_missing_plugins_foo (const GList * missing_plugins, MsgToStrFunc func)
{
  GPtrArray *arr = g_ptr_array_new ();
  GHashTable *ht;

  ht = g_hash_table_new (g_str_hash, g_str_equal);
  while (missing_plugins != NULL) {
    char *tmp;
    tmp = func (GST_MESSAGE (missing_plugins->data));
    if (!g_hash_table_lookup (ht, tmp)) {
      g_ptr_array_add (arr, tmp);
      g_hash_table_insert (ht, tmp, GINT_TO_POINTER (1));
    } else {
      g_free (tmp);
    }
    missing_plugins = missing_plugins->next;
  }
  g_ptr_array_add (arr, NULL);
  g_hash_table_destroy (ht);
  return (gchar **) g_ptr_array_free (arr, FALSE);
}

gchar ** bvw_get_missing_plugins_descriptions (const GList * missing_plugins)
{
  return bvw_get_missing_plugins_foo (missing_plugins,
      gst_missing_plugin_message_get_description);
}
}//anonymous namespace

void BaconVideoWidget::Impl::clear_missing_plugins_messages()
{
    if(missing_plugins_!=NULL){

        g_list_free_full (missing_plugins_, (GDestroyNotify) gst_mini_object_unref);
        missing_plugins_ = NULL;

    }
}

GError* BaconVideoWidget::Impl::bvw_error_from_gst_error(GstMessage * err_msg)
{
  const gchar *src_typename;
  GError *ret = NULL;
  GError *e = NULL;
  char *dbg = NULL;

  // GST_LOG ("resolving %" GST_PTR_FORMAT, err_msg);
  src_typename = (err_msg->src) ? G_OBJECT_TYPE_NAME (err_msg->src) : NULL;
  gst_message_parse_error (err_msg, &e, &dbg);
  
  if (src_typename &&
      g_str_equal (src_typename, "GstGtkGLSink") &&
      is_error (e, RESOURCE, NOT_FOUND)) 
  {
    media_has_unsupported_video_ = TRUE;
    ret = g_error_new_literal (BVW_ERROR, static_cast<gint>(BVW_ERROR_GENERIC),
			      "Could not initialise OpenGL support.");
    set_current_actor();
    goto done;
  }

  if (is_error (e, CORE, MISSING_PLUGIN) ||
      is_error (e, STREAM, CODEC_NOT_FOUND) ||
      is_error (e, STREAM, WRONG_TYPE) ||
      is_error (e, STREAM, NOT_IMPLEMENTED) ||
      (is_error (e, STREAM, FORMAT) && strstr (dbg, "no video pad or visualizations"))) 
  {
    if (missing_plugins_ != NULL) {
      gchar **descs, *msg = NULL;
      guint num;

      descs = bvw_get_missing_plugins_descriptions (missing_plugins_);
      num = g_list_length (missing_plugins_);

      if (is_error (e, CORE, MISSING_PLUGIN)) 
      {
        /* should be exactly one missing thing (source or converter) */
        msg = g_strdup_printf ("The playback of this movie requires a %s "
				 "plugin which is not installed.", descs[0]);
	ret = g_error_new_literal (BVW_ERROR, static_cast<gint>(BVW_ERROR_NO_PLUGIN_FOR_FILE), msg);
	g_free (msg);
      } else {
        gchar *desc_list;

        desc_list = g_strjoinv ("\n", descs);
        if (num == 1)
        {
          msg = g_strdup_printf("The playback of this movie requires a %s plugin which is not installed.",descs[0]);
        }
        else
        {
          msg = g_strdup_printf("The playback of this movie requires the following plugins which are not installed:\n\n%s",desc_list);

        }
        g_free (desc_list);
	ret = g_error_new_literal (BVW_ERROR, static_cast<gint>(BVW_ERROR_CODEC_NOT_HANDLED), msg);
	g_free (msg);
      }
      g_strfreev (descs);
    } else {

	      ret = g_error_new_literal (BVW_ERROR, static_cast<gint>(BVW_ERROR_CODEC_NOT_HANDLED),
				  "An audio or video stream is not handled due to missing codecs. "
          "You might need to install additional plugins to be able to play some types of movies");
      
    }
    goto done;
  }

  if (is_error (e, STREAM, FAILED) &&
	     src_typename &&
	     strncmp (src_typename, "GstTypeFind", 11) == 0) {
    ret = g_error_new_literal (BVW_ERROR, static_cast<gint>(BVW_ERROR_READ_ERROR),
			      "This file cannot be played over the network. Try downloading it locally first.");
    goto done;
  }

  /* generic error, no code; take message */
  ret = g_error_new_literal (BVW_ERROR, static_cast<gint>(BVW_ERROR_GENERIC),
			     e->message);

done:
  g_error_free (e);
  g_free (dbg);
  clear_missing_plugins_messages();

  return ret;
}

//Used in GST_MESSAGE_STATE_CHANGED 
void BaconVideoWidget::Impl::show_error_if_video_decoder_is_missing ()
{
  GList *l;

  if (media_has_video_ || missing_plugins_ == NULL)
  {
      return;
  }

  for (l = missing_plugins_; l != NULL; l = l->next) 
  {
    GstMessage *msg = GST_MESSAGE (l->data);
    gchar *d, *f;

    if ((d = gst_missing_plugin_message_get_installer_detail (msg))) {
      if ((f = strstr (d, "|decoder-")) && strstr (f, "video")) {
        GError *err;
        /* create a fake GStreamer error so we get a nice warning message */
        err = g_error_new (GST_CORE_ERROR, GST_CORE_ERROR_MISSING_PLUGIN, "x");
        msg = gst_message_new_error (GST_OBJECT (pipeline_), err, NULL);
        g_error_free (err);

        err = bvw_error_from_gst_error(msg);
        gst_message_unref (msg);

        // wrap a C-style GError* into a C++ Glib::Error
        Glib::Error coverted = Glib::Error(err);

        //Populate this error via signal
        signal_error_.emit(coverted.what().c_str(), false/*playback_stopped*/);
        //since wrapped in c++, no manually free its underlying c obj
        // g_error_free (err);
        g_free (d);
        break;
      }
      g_free (d);
    }
  }
}



void BaconVideoWidget::Impl::check_if_video_decoder_is_missing ()
{
  GList *l;

  for (l = missing_plugins_; l != NULL; l = l->next) {
    GstMessage *msg = GST_MESSAGE (l->data);
    g_autofree char *d = NULL;
    char *f;

    if ((d = gst_missing_plugin_message_get_installer_detail (msg))) {
      if ((f = strstr (d, "|decoder-")) && strstr (f, "video")) {
        media_has_unsupported_video_ = TRUE;
        break;
      }
    }
  }
}


//used in GST_MESSAGE_ERROR
bool BaconVideoWidget::Impl::check_missing_plugins_error (GstMessage * err_msg)
{
  gboolean error_src_is_pipeline;
  GError *err = NULL;

  if (missing_plugins_ == NULL) {
    // GST_DEBUG ("no missing-plugin messages");
    return FALSE;
  }

  gst_message_parse_error (err_msg, &err, NULL);

  error_src_is_pipeline = (err_msg->src == GST_OBJECT_CAST (pipeline_));

  if (is_error (err, CORE, MISSING_PLUGIN) ||
      is_error (err, STREAM, CODEC_NOT_FOUND) ||
      (is_error (err, STREAM, WRONG_TYPE) && error_src_is_pipeline)) {
    check_if_video_decoder_is_missing ();
    set_current_actor();
  } else {
    // GST_DEBUG ("not an error code we are looking for, doing nothing");
  }

  g_error_free (err);
  return FALSE;
}

//used in GST_MESSAGE_ERROR
bool BaconVideoWidget::Impl::check_mpeg_eos (GstMessage *err_msg)
{
                        printf ("(bvw_check_mpeg_eos) \n");
  gboolean ret = FALSE;
  g_autoptr(GError) err = NULL;
  g_autofree char *dbg = NULL;

  gst_message_parse_error (err_msg, &err, &dbg);

  /* Error from gst-libs/gst/video/gstvideodecoder.c
   * thrown by mpeg2dec */
  if (err != NULL &&
      dbg != NULL &&
      is_error (err, STREAM, DECODE) &&
      strstr (dbg, "no valid frames found")) 
  {
    if (eos_tag_.connected() == false) 
    {
       eos_tag_ =  Glib::signal_idle().connect(sigc::mem_fun(*this, &Impl::signal_eos_delayed));

    } else 
    {
        // GST_DEBUG ("Not throwing EOS instead of an error when seeking to the end of an MPEG file, EOS already planned");
    }
    ret = TRUE;
  }

  return ret;
}




/************Gstreamer Bus communication*************/

void BaconVideoWidget::Impl::handle_application_message(GstMessage *msg)
{
    const GstStructure *structure;
    const gchar *type_name = NULL;
    gchar *src_name;

    g_return_if_fail (GST_IS_MESSAGE (msg));
  
    src_name = gst_object_get_name (GST_OBJECT_CAST(msg->src));
  
    printf("(bvw_handle_application_message) entering \n");

    structure = gst_message_get_structure (msg);
  
    g_return_if_fail (GST_IS_STRUCTURE (structure));

    if (structure)
    {
        type_name = gst_structure_get_name (structure);

                                // printf("(bvw_handle_application_message) src_name is:%s,type_name is:%s \n", src_name, type_name);
    }
    
    if (type_name == NULL)
    {
        goto unhandled;
    }


unhandled:
    // GST_WARNING ("Unhandled element message %s from %s: %" GST_PTR_FORMAT,
                  // GST_STR_NULL (type_name), GST_STR_NULL (src_name), msg);

done:
    //// gst_structure_free (structure);
    g_free (src_name);

}





void BaconVideoWidget::Impl::handle_element_message(GstMessage *msg)
{
  const GstStructure *structure;
  const gchar *type_name = NULL;
  gchar* src_name;
  g_return_if_fail (GST_IS_MESSAGE (msg));

  src_name = gst_object_get_name (msg->src);

  // Returns: (transfer none) 
  structure = gst_message_get_structure (msg);
  g_return_if_fail (GST_IS_STRUCTURE (structure));
  if (structure)
  {
    type_name = gst_structure_get_name (structure);
                                // printf("(bvw_handle_element_message) src_name is:%s,type_name is:%s \n",  src_name, type_name);
  }

  if (type_name == NULL)
  {
    goto unhandled;
  }

  //collect missing plugins
  if (gst_is_missing_plugin_message (msg)) 
  {
                                printf("(bvw_handle_element_message) Got one missing plugin msg \n");
    missing_plugins_ =
      g_list_prepend (missing_plugins_, gst_message_ref (msg));
    goto done;
  } 

unhandled:
  // GST_WARNING ("Unhandled element message %s from %s: %" GST_PTR_FORMAT,
  //     GST_STR_NULL (type_name), GST_STR_NULL (src_name), msg);
      // printf ("(bvw_handle_element_message) Unhandled element message %s from %s:%" GST_PTR_FORMAT " \n", 
                // GST_STR_NULL (type_name), GST_STR_NULL (src_name),  static_cast<void*>(msg));
done:
    g_free (src_name);
}



void BaconVideoWidget::Impl::bus_message_cb_function(GstBus * bus, GstMessage * message, gpointer user_data)
{
  BaconVideoWidget::Impl* self = static_cast<BaconVideoWidget::Impl*>(user_data);
  if (self) 
  {
    self->bus_message_cb_method(bus, message);
  }
}

void BaconVideoWidget::Impl::bus_message_cb_method(GstBus * bus, GstMessage * message)
{
  GstMessageType msg_type;

  msg_type = GST_MESSAGE_TYPE (message);

  if (msg_type != GST_MESSAGE_STATE_CHANGED) {
    gchar *src_name = gst_object_get_name (GST_OBJECT_CAST(message->src));

    // GST_LOG ("Handling %s message from element %s",
    //     gst_message_type_get_name (msg_type), src_name);

                            // printf("(bvw_bus_message_cb) Handling %s message from element %s \n",
                            //  gst_message_type_get_name (msg_type), src_name );

    g_free (src_name);
  }

  switch (msg_type) 
  {  
    case GST_MESSAGE_ERROR: 
    {
                  printf("(bvw_bus_message_cb) GST_MESSAGE_ERROR: \n");
      totem_gst_message_print (message, pipeline_, "totem-error");

      if (!check_missing_plugins_error (message) &&
	        !check_mpeg_eos(message)) {
        GError *error;
        error = bvw_error_from_gst_error (message);
        target_state_ = GST_STATE_NULL;
        if (pipeline_)
          gst_element_set_state (pipeline_, GST_STATE_NULL);
        buffering_ = FALSE;
        // g_signal_emit (bvw, bvw_signals[SIGNAL_ERROR], 0,
        //                error->message, TRUE);
        signal_error_.emit(error->message, TRUE);
        g_error_free (error);
      }
      break;
    }

    case GST_MESSAGE_WARNING: 
    {
      GST_WARNING ("Warning message: %" GST_PTR_FORMAT ,  static_cast<void*>(message));
      break;
    }

    case GST_MESSAGE_TAG: 
      /* Ignore TAG messages, we get updated tags from the
       * GST_EVENT_TAG in bvw_decodebin_video_outpad_event 
       * or decodebin_audio_outpad_event_function
       */
      break;

    case GST_MESSAGE_EOS:
    {
      // GST_DEBUG ("EOS message");
      
              printf("(bvw_bus_message_cb) Got EOS Message \n");

      /* update slider one last time */
      query_timeout();
      Glib::signal_idle().connect(sigc::mem_fun(*this, &Impl::signal_eos_delayed));
      break;
    }

    case GST_MESSAGE_BUFFERING:
    {
        // printf("bvw_bus_message_cb GST_MESSAGE_BUFFERING \n");
      handle_buffering_message(message);
      break;
    }

    case GST_MESSAGE_APPLICATION: 
    {
          // printf ("#handle GST_MESSAGE_APPLICATION BEGIN \n");
          handle_application_message(message);
          // printf ("#handle GST_MESSAGE_APPLICATION END \n");

      break;
    }



    //**************************************might posted in gstbasesink.c***************************************
    case GST_MESSAGE_STATE_CHANGED: 
    {
      GstState old_state, new_state;
      gchar *src_name;

      gst_message_parse_state_changed (message, &old_state, &new_state, NULL);

      if (old_state == new_state)
      {
        break;
      }

      /* we only care about pipeline_'s state changes */
      if (GST_MESSAGE_SRC (message) != GST_OBJECT (pipeline_))
      {
        break;
      }

      src_name = gst_object_get_name (GST_OBJECT_CAST(message->src));


      
      /*
such as 
when bvw-pipeline change state from READY to PAUSED, this happends when moov header got, and decodebin's out pad added (bvw/on_pad_added for decodebin

when bvw-pipeline changed state from PLAYING to PAUSED(press Pause Button ), this will block at push_loop on gst_pad_push()......in gst_bt_demux_push_loop()

      */



                  printf("(bvw_bus_message_cb) %s changed state from %s to %s\n", 
                      src_name,
                      gst_element_state_get_name (old_state),
                      gst_element_state_get_name (new_state)
                      );

      // GST_DEBUG ("%s changed state from %s to %s", src_name,
      //     gst_element_state_get_name (old_state),
      //     gst_element_state_get_name (new_state));
      g_free (src_name);


      /* now do stuffs */
      if (new_state <= GST_STATE_PAUSED) 
      {
          //under these circumstances we will disable updating slider and time label
          //We Press Pause button or During a seek operation when async_done not happened

              printf ("(bvw_bus_message_cb) disable updating slider and time label\n");

        /* update slider one last time */
        query_timeout();
        //disable updating slider&time label every period of time
        reconfigure_tick_timeout(0);
      } else if (new_state > GST_STATE_PAUSED) 
      {

              printf ("(bvw_bus_message_cb) resume updating slider and time label\n");

        /*resume update slider and time label periodically*/
        reconfigure_tick_timeout(200);
      }

      //state changed from READY to PAUSED, maybe it is start playing
      if (old_state == GST_STATE_READY && new_state == GST_STATE_PAUSED) 
      {
                    
                    //// GST_DEBUG_BIN_TO_DOT_FILE (GST_BIN_CAST (pipeline_),
                    ////     GST_DEBUG_GRAPH_SHOW_ALL ^ GST_DEBUG_GRAPH_SHOW_NON_DEFAULT_PARAMS,
                    ////     "totem-prerolled");

        /*gint64 stream_length = */
                update_and_get_stream_length ();

                  /*printf("(bvw_bus_message_cb) In GST_MESSAGE_STATE_CHANGED: stream len = %ld\n", stream_length);*/

        update_stream_info();
        /* show a non-fatal warning message if we can't decode the video */
        show_error_if_video_decoder_is_missing();
        /* Now that we have the length, check whether we wanted
        * to pause or to stop the pipeline even after we start get data of the video and can play*/
        if (target_state_ == GST_STATE_PAUSED)
        {
                  printf("(bvw_bus_message_cb) GST_MESSAGE_STATE_CHANGED, next line call bacon_video_widget_pause\n");

	        pause();
        }
      } 
      //state changed from PAUSED back to READY, maybe it is played and reach EOS
      else if (old_state == GST_STATE_PAUSED && new_state == GST_STATE_READY) 
      {

                printf ("(bvw_bus_message_cb) pipeline state changed from PAUSED back to READY, clear related tags cache \n");

        media_has_video_ = FALSE;
        media_has_audio_ = FALSE;
	      media_has_unsupported_video_ = FALSE;

        /* clean metadata cache */
        g_clear_pointer (&tagcache_,  gst_tag_list_unref);
        gst_tag_list_unref(property_our_audio_tags_.get_value());
        property_our_audio_tags_.set_value(NULL);
        gst_tag_list_unref(property_our_video_tags_.get_value());
        property_our_video_tags_.set_value(NULL);

        video_width_ = 0;
        video_height_ = 0;
      }
      break;
    }
    /*******************************************************************************/

    case GST_MESSAGE_ELEMENT: 
    {
      handle_element_message(message);
      break;
    }

    //happens when user trigger a seek ,or loading stream whose moov header after mdat case
    case GST_MESSAGE_ASYNC_DONE: 
    {
	    gint64 _time;
      /* When a seek has finished, set the playing state again */
      g_mutex_lock (&seek_mutex_);/*********************************************/

      seek_req_time_ = gst_clock_get_internal_time (clock_);
      //Steal seek_time. if it is not -1, means that it is a queued seek, we should finish it and reset it to -1
      _time = seek_time_;
      seek_time_ = -1;

	    g_mutex_unlock (&seek_mutex_);/*******************************************/

      if (_time >= 0) {
              printf("(bvw_bus_message_cb) In GST_MESSAGE_ASYNC_DONE case: Have an old seek (%" GST_TIME_FORMAT ") to schedule, doing it now\n",
                  GST_TIME_ARGS (_time * GST_MSECOND));
        // GST_DEBUG ("Have an old seek to schedule, doing it now");
        seek_time_no_lock(_time, GST_SEEK_FLAG_NONE, NULL);
      } 
      //we do not press "Pause" button before seek, 
      //so resume playing then seek success, cuz we Pause the pipeline in bacon_video_widget_seek_time_no_lock()
      else if(target_state_ == GST_STATE_PLAYING) {

              printf("(bvw_bus_message_cb) In GST_MESSAGE_ASYNC_DONE case: Maybe starting deferred playback after seek\n");

        // GST_DEBUG ("Maybe starting deferred playback after seek");
        play(NULL);
      }

	    update_and_get_stream_length();
      update_and_get_seekable();
      break;
    }

    /* FIXME: at some point we might want to handle CLOCK_LOST and set the
     * pipeline back to PAUSED and then PLAYING again to select a different
     * clock (this seems to trip up rtspsrc though so has to wait until
     * rtspsrc gets fixed) */
    case GST_MESSAGE_CLOCK_PROVIDE:
    case GST_MESSAGE_CLOCK_LOST:
    case GST_MESSAGE_NEW_CLOCK:
    case GST_MESSAGE_STATE_DIRTY:
    case GST_MESSAGE_STREAM_STATUS:
      break;

    case GST_MESSAGE_UNKNOWN:
    case GST_MESSAGE_INFO:
    case GST_MESSAGE_STEP_DONE:
    case GST_MESSAGE_STRUCTURE_CHANGE:
    case GST_MESSAGE_SEGMENT_START:
    case GST_MESSAGE_SEGMENT_DONE:
    case GST_MESSAGE_LATENCY:
    case GST_MESSAGE_ASYNC_START:
    case GST_MESSAGE_REQUEST_STATE:
    case GST_MESSAGE_STEP_START:
    case GST_MESSAGE_QOS:
    case GST_MESSAGE_PROGRESS:
    case GST_MESSAGE_ANY:
    case GST_MESSAGE_RESET_TIME:
    case GST_MESSAGE_STREAM_START:
    case GST_MESSAGE_NEED_CONTEXT:
    case GST_MESSAGE_HAVE_CONTEXT:
    default:
      GST_LOG ("Unhandled message: %" GST_PTR_FORMAT, static_cast<void*>(message));
      break;
  }
}



bool BaconVideoWidget::Impl::signal_eos_delayed()
{
  signal_eos_.emit();
  return FALSE;
}


/*this func is to configure enable/disable updating slider and time label*/
void BaconVideoWidget::Impl::reconfigure_tick_timeout(guint msecs)
{
  if (update_timer_.connected() != false) {

              printf ("(bvw_reconfigure_tick_timeout) removing tick timeout \n");
              update_timer_.disconnect();

    // GST_DEBUG ("removing tick timeout");
    // g_source_remove (update_id_);
    // update_id_ = 0;
  }
  if (msecs > 0) {

              printf ("(bvw_reconfigure_tick_timeout) adding tick timeout (at %ums) \n", msecs);

    // GST_DEBUG ("adding tick timeout (at %ums)", msecs);
   
    update_timer_ = Glib::signal_timeout().connect(sigc::mem_fun(*this, &Impl::query_timeout), msecs);

  }
}




/*Actually update time label and slider progress bar*/
bool BaconVideoWidget::Impl::query_timeout()
{
  gint64 pos = -1;

  /* check stream position in nanoseconds 
  a value between 0 and the stream duration (if the stream duration is known)
  */
  if (gst_element_query_position(pipeline_, GST_FORMAT_TIME, &pos)) {
    if (pos != -1) {
      //Emit a time tick of where we are going
      got_time_tick(GST_ELEMENT (pipeline_), pos);
    } else {
      printf ("(bvw_query_timeout) get negative position\n");

    }
  } else {
      printf ("(bvw_query_timeout) could not get position\n");
    // GST_DEBUG ("could not get position");
  }
                  //printf("(bvw_query_timeout) pos=%ld \n", pos);

  return TRUE;
}



void BaconVideoWidget::Impl::got_time_tick(GstElement * element, gint64 time_nanos)
{
  gboolean seekable;

  gint old_seekable = seekable_;

  //this is in milliseconds
  current_time_ = (gint64) time_nanos / GST_MSECOND;

          // printf("(bacon_video_widget/GOT_TIME_TICK) current_time_ = %ld \n", current_time_);

  //stream_length_ is "zero", which is initial value, means that we do not get the stream_length yet
  if (stream_length_ == 0) 
  {
    current_position_ = 0;
  } 
  else 
  {
    current_position_ = 
            (gdouble) current_time_ / stream_length_;
  }

  //stream_length_ is "zero", which is initial value, means that we do not get the stream_length yet
  if (stream_length_ == 0) 
  {
    seekable = update_and_get_seekable();
  } 
  else 
  {
    //if we have stream_length received, we can count it as seekable, it is a Guess ! 
    //if seekable is unknow, which is the initial value,if not modified
    if (seekable_ == -1)
    {
      //let totem's property_notify_cb_seekable() be called
      // g_object_notify (G_OBJECT (bvw), "seekable");
      property_seekable_.notify();
    }
    seekable = TRUE;
  }

/*
  GST_DEBUG ("current time: %" GST_TIME_FORMAT ", stream length: %" GST_TIME_FORMAT ", seekable: %s",
      GST_TIME_ARGS (current_time_ * GST_MSECOND),
      GST_TIME_ARGS (stream_length_ * GST_MSECOND),
      (seekable) ? "TRUE" : "FALSE");
*/


#if 2 
    if (old_seekable == -1 && seekable_ > -1)
    {
      printf ("(got_time_tick) From now on, (Initial) the stream become %sseekable \n", (seekable_==1)? "" : "not ");
    }
    else if (old_seekable == 1 && seekable_ == 0)
    {
      printf ("(got_time_tick) From now on, the stream become from seekable to NOT seekable \n");
    }
    else if (old_seekable == 0 && seekable_ == 1)
    {
      printf ("(got_time_tick) From now on, the stream become from NON-seekable to seekable \n");
    }
#endif 


  // g_signal_emit (bvw, bvw_signals[SIGNAL_TICK], 0,
  //                current_time_, stream_length_,
  //                current_position_,
  //                seekable);


  signal_tick_.emit(current_time_, stream_length_, current_position_, seekable);
}


/*Handling Three-Piece-Area Buffering msg from btdemux*/
void BaconVideoWidget::Impl::handle_buffering_message(GstMessage * message)
{
  gint percent = 0;

  gst_message_parse_buffering (message, &percent);

  /**********Three-Piece-Area Buffered finished***********/
  if (percent >= 100) 
  {
    /* a 100% message means buffering is done */
    buffering_ = FALSE;
    /* if the desired state is playing, go back */
    if (target_state_ == GST_STATE_PLAYING) 
    {
      // GST_DEBUG ("Buffering done, setting pipeline back to PLAYING");
                printf("(bvw_handle_buffering_message) Buffering done, call bacon_video_widget_play on it\n");
      play(NULL);
    } 
    else 
    {
      // GST_DEBUG ("Buffering done, keeping pipeline PAUSED");
                printf("(bvw_handle_buffering_message) Buffering done, keeping pipeline PAUSED\n");
    }
  } 

  /**********Three-Piece-Area Buffered not finished And we are not paused***********/
  else if (target_state_ == GST_STATE_PLAYING) 
  {
    GstState cur_state;

    gst_element_get_state (pipeline_, &cur_state, NULL, 0);
    if (cur_state != GST_STATE_PAUSED) 
    {
      // GST_DEBUG ("Buffering ... temporarily pausing playback %d%%", percent);
      
                printf("(bvw_handle_buffering_message) Buffering... temporarily pausing playback %d%% and SET pipeline_ state to PAUSED\n", percent);

      gst_element_set_state (pipeline_, GST_STATE_PAUSED);
    } 
    else 
    {
                printf("(bvw_handle_buffering_message) Buffering (already paused) ... %d%%\n", percent);
      // GST_LOG ("Buffering (already paused) ... %d%%", percent);
    }
    buffering_ = TRUE;
  } 

  /**********Three-Piece-Area Buffered not finished And we've already let paused , do nothing and just report the progress***********/
  else 
  {
    // GST_LOG ("Buffering ... %d", percent);
                printf("(bvw_handle_buffering_message)Buffering ... %d\n", percent);
    buffering_ = TRUE;
  }
}








/******************/
//video-changed or audio-changed

void BaconVideoWidget::Impl::update_stream_info()
{
              // printf("(bvw_update_stream_info) \n");

  parse_stream_info();

printf ("(bvw_update_stream_info) emit got-metadata \n");

  // g_signal_emit(bvw, bvw_signals[SIGNAL_GOT_METADATA], 0, NULL);
  signal_got_metadata_.emit();
}

//doing some small stuff (mainly to get video decoder caps "framerate","width", "height") after gstdecodebin2 srcpads(audio/video) added
void BaconVideoWidget::Impl::parse_stream_info()
{
  GstPad *video_pad = NULL;
  gint n_video, n_audio;

  n_video = video_channels_ ? video_channels_->len : 0;
  n_audio = audio_channels_ ? audio_channels_->len : 0;

  media_has_video_ = FALSE;

  if (n_video > 0) 
  {
    gint i;

    media_has_video_ = TRUE;
    for(i=0; i<n_video && video_pad==NULL; i++)
    {
      video_pad = static_cast<GstPad*>(g_ptr_array_index(video_channels_, i));
    }
  }

  media_has_audio_ = (n_audio > 0);

  if (video_pad) 
  {
    GstCaps *caps;

    if ((caps = gst_pad_get_current_caps (video_pad))) 
    {
      caps_set_method(G_OBJECT (video_pad));
      gst_caps_unref (caps);
    }

    //"caps" property defined in #GstPad (see gstpad.c)
    g_signal_connect (video_pad, "notify::caps", G_CALLBACK (caps_set_function), this);

    //dont unref it prematurely, it managed within in gstdecodebin2
    //// gst_object_unref (video_pad);
  }

  set_current_actor();
}

//get video deocder (who is outpad of gstdecodebin2) caps, so we can know metadata such as framerate, and video width/height...
void BaconVideoWidget::Impl::caps_set_function (GObject * obj, GParamSpec * pspec, gpointer user_data)
{

  BaconVideoWidget::Impl* self = static_cast<BaconVideoWidget::Impl*>(user_data);
  if (self) self->caps_set_method(obj);

}

void BaconVideoWidget::Impl::caps_set_method (GObject * obj)
{

  GstPad *pad = GST_PAD (obj);
  GstStructure *s;
  GstCaps *caps;

  if (!(caps = gst_pad_get_current_caps (pad)))
  {
        printf ("(caps_set) caps on video pad is empty \n");
    return;
  }

  /* Get video decoder caps */
  s = gst_caps_get_structure (caps, 0);
  if (s) {
    /* We need at least width/height and framerate */
    if (!(gst_structure_get_fraction (s, "framerate", &video_fps_n_,
          &video_fps_d_) &&
          gst_structure_get_int (s, "width", &video_width_) &&
          gst_structure_get_int (s, "height", &video_height_)))
    {
      printf ("(caps_set) Failed to get video decoder caps \n");
      return;
    } 
    else 
    {
      printf ("(caps_set) video decoder caps: fps_n: %d, fps_d: %d, width: %d, height: %d \n", 
        video_fps_n_,
        video_fps_d_,
        video_width_,
        video_height_);
    }
  }

  gst_caps_unref (caps);
}





gint64 BaconVideoWidget::update_and_get_stream_length()
{
  return impl_->update_and_get_stream_length();
}

gint64 BaconVideoWidget::Impl::update_and_get_stream_length()
{

  //stream_length_ is "zero", which is initial value, means that we do not get the stream_length yet
  //[If stream_length is not set, Then query and set it]
  if (stream_length_ == 0 && pipeline_ != NULL) {
    gint64 len = -1;

    // get total stream duration in nanoseconds
    if (gst_element_query_duration (decodebin_, GST_FORMAT_TIME, &len) && len != -1) {
      //in milliseconds
      stream_length_ = len / GST_MSECOND;
    }
  }

  // Be careful! it is in milliseconds !!!
  //0:stream_length failed to query
  //non-zero:ok to get stream_length 
  return stream_length_;

}




gint64 BaconVideoWidget::get_current_time()
{
  return impl_->get_current_time();
}
gint64 BaconVideoWidget::Impl::get_current_time()
{
  //get the current time posistion of playing stream, used for serialization,saving playling stat for resume next time 
  return current_time_;
}


























































/*******************************************PUBLIC METHODS**************************************************/
GObject* BaconVideoWidget::fetch_btdemux()
{
    return impl_->fetch_btdemux();
}

GObject* BaconVideoWidget::Impl::fetch_btdemux()
{
    if(btdemux_)
    {
        return G_OBJECT(btdemux_);
    }

    return NULL;
}




bool BaconVideoWidget::check_gstreamer_init(Glib::Error& error)
{
    return impl_->check_gstreamer_init(error);
}

bool BaconVideoWidget::Impl::check_gstreamer_init(Glib::Error& error)
{
    if (!gst_init_errors_)
        return true;
    //populate via copy assignment
    error = gst_init_errors_;
    return false;
}


bool BaconVideoWidget::check_pipeline_init(Glib::Error& error)
{
    return impl_->check_pipeline_init(error);
}

bool BaconVideoWidget::Impl::check_pipeline_init(Glib::Error& error)
{
    if (!init_error_)
        return true;
    //populate via copy assignment
    error = init_error_;
    return false;
}



//Exposed signals
sigc::signal<void(const char*, bool)>& BaconVideoWidget::signal_error()
{
    return impl_->signal_error();
}
sigc::signal<void(const char*, bool)>& BaconVideoWidget::Impl::signal_error()
{
    return signal_error_;
}


sigc::signal<void()>& BaconVideoWidget::signal_eos()
{
    return impl_->signal_eos();
}
sigc::signal<void()>& BaconVideoWidget::Impl::signal_eos()
{
    return signal_eos_;
}


sigc::signal<void(std::int64_t, std::int64_t, double, bool)>& BaconVideoWidget::signal_tick()
{
    return impl_->signal_tick();
}
sigc::signal<void(std::int64_t, std::int64_t, double, bool)>& BaconVideoWidget::Impl::signal_tick()
{
    return signal_tick_;
}

sigc::signal<void()>& BaconVideoWidget::signal_play_starting()
{
    return impl_->signal_play_starting();
}
sigc::signal<void()>& BaconVideoWidget::Impl::signal_play_starting()
{
    return signal_play_starting_;
}


sigc::signal<void()>& BaconVideoWidget::signal_got_metadata()
{
    return impl_->signal_got_metadata();
}
sigc::signal<void()>& BaconVideoWidget::Impl::signal_got_metadata()
{
    return signal_got_metadata_;
}




sigc::signal<void()>& BaconVideoWidget::signal_btdemux_destructing()
{
    return impl_->signal_btdemux_destructing();
}
sigc::signal<void()>& BaconVideoWidget::Impl::signal_btdemux_destructing()
{
    return signal_btdemux_destructing_;
}




//Exposed properties
Glib::PropertyProxy<bool> BaconVideoWidget::property_seekable()
{
    return impl_->property_seekable().get_proxy();
}
Glib::Property<bool>& BaconVideoWidget::Impl::property_seekable()
{
    return property_seekable_;
}


Glib::PropertyProxy<double> BaconVideoWidget::property_volume()
{
    return impl_->property_volume().get_proxy();
}
Glib::Property<double>& BaconVideoWidget::Impl::property_volume()
{
    return property_volume_;
}


Glib::PropertyProxy<std::string> BaconVideoWidget::property_audio_output_type()
{
    return impl_->property_audio_output_type().get_proxy();
}
Glib::Property<std::string>& BaconVideoWidget::Impl::property_audio_output_type()
{
    return property_audio_output_type_;
}




Glib::PropertyProxy<int> BaconVideoWidget::property_color_balance_contrast()
{
    return impl_->property_color_balance_contrast().get_proxy();
}
Glib::Property<int>& BaconVideoWidget::Impl::property_color_balance_contrast()
{
    return property_color_balance_contrast_;
}

Glib::PropertyProxy<int> BaconVideoWidget::property_color_balance_saturation()
{
    return impl_->property_color_balance_saturation().get_proxy();
}
Glib::Property<int>& BaconVideoWidget::Impl::property_color_balance_saturation()
{
    return property_color_balance_saturation_;
}

Glib::PropertyProxy<int> BaconVideoWidget::property_color_balance_brightness()
{
    return impl_->property_color_balance_brightness().get_proxy();
}
Glib::Property<int>& BaconVideoWidget::Impl::property_color_balance_brightness()
{
    return property_color_balance_brightness_;
}

Glib::PropertyProxy<int> BaconVideoWidget::property_color_balance_hue()
{
    return impl_->property_color_balance_hue().get_proxy();
}
Glib::Property<int>& BaconVideoWidget::Impl::property_color_balance_hue()
{
    return property_color_balance_hue_;
}


void BaconVideoWidget::Impl::set_color_balance_contrast()
{
  int val = property_color_balance_contrast_.get_value();
  set_video_property(BvwVideoProperty::BVW_VIDEO_CONTRAST, val);
}

void BaconVideoWidget::Impl::set_color_balance_saturation()
{
  int val = property_color_balance_saturation_.get_value();
  set_video_property(BvwVideoProperty::BVW_VIDEO_SATURATION, val);
}

void BaconVideoWidget::Impl::set_color_balance_brightness()
{
  int val = property_color_balance_brightness_.get_value();
  set_video_property(BvwVideoProperty::BVW_VIDEO_BRIGHTNESS, val);
}

void BaconVideoWidget::Impl::set_color_balance_hue()
{
  int val = property_color_balance_hue_.get_value();
  set_video_property(BvwVideoProperty::BVW_VIDEO_HUE, val);
}


void BaconVideoWidget::Impl::on_audio_output_type_changed()
{
  std::string enum_nick_str = property_audio_output_type_.get_value();
printf ("(on_audio_output_type_changed) Cur: %s \n", enum_nick_str.c_str());
  //gschemas store audio-output-type as its enum nick string, we need map back to its enum val
  BvwAudioOutputType enum_val = BVW_AUDIO_SOUND_STEREO;
  if (enum_nick_str == "stereo")  enum_val= BVW_AUDIO_SOUND_STEREO;
  else if (enum_nick_str == "4channel") enum_val=  BVW_AUDIO_SOUND_4CHANNEL;
  else if (enum_nick_str == "41channel") enum_val=  BVW_AUDIO_SOUND_41CHANNEL;
  else if (enum_nick_str == "5channel") enum_val=  BVW_AUDIO_SOUND_5CHANNEL;
  else if (enum_nick_str == "51channel") enum_val=  BVW_AUDIO_SOUND_51CHANNEL;
  else if (enum_nick_str == "ac3passthru") enum_val=  BVW_AUDIO_SOUND_AC3PASSTHRU;

  set_audio_output_type(enum_val);
}










//metadata tags


//for audio caps
gboolean BaconVideoWidget::Impl::audio_caps_have_LFE(GstStructure* s)
{
  guint64 mask;
  int channels;

  if (!gst_structure_get_int (s, "channels", &channels) ||
      channels == 0)
    return FALSE;

  if (!gst_structure_get (s, "channel-mask", GST_TYPE_BITMASK, &mask, NULL))
    return FALSE;

  if (mask & GST_AUDIO_CHANNEL_POSITION_LFE1 ||
      mask & GST_AUDIO_CHANNEL_POSITION_LFE2)
    return TRUE;

  return FALSE;
}






GstCaps* BaconVideoWidget::Impl::get_caps_of_current_stream(StreamType type)
{
  GstCaps *caps = NULL;
  gint stream_num = -1;
  GstPad *current = NULL;

  stream_num = get_current_stream_num(type);
  if (stream_num < 0)
  {
    return NULL;
  }

  //index is num minue one
  if(type == StreamType::STREAM_TYPE_AUDIO)
  {
    current =  static_cast<GstPad*>(g_ptr_array_index(audio_channels_, stream_num-1));
  }
  else if(type == StreamType::STREAM_TYPE_VIDEO)
  {
    current =  static_cast<GstPad*>(g_ptr_array_index(video_channels_, stream_num-1));
  }

  if (current != NULL) 
  {
    // Returns: (transfer full) (nullable)
    caps = gst_pad_get_current_caps (current);
        // printf ("(bvw_get_caps_of_current_stream) Get caps ok  %d %d %d\n",stream_num, audio_channels_->len, video_channels_->len);
  }
  else
  {
        // printf ("(bvw_get_caps_of_current_stream) Failed get pad from channels %d %d %d\n",stream_num, audio_channels_->len, video_channels_->len);
  }

  // GST_LOG ("current %s stream caps: %" GST_PTR_FORMAT, stream_type, caps);

  return caps;
}




//happens right after [mmov] header parsed
void BaconVideoWidget::Impl::update_tags(GstTagList *tag_list, StreamType type)
{
  GstTagList **cache = NULL;
  GstTagList *result;
  GstTagList* tags_target = NULL;
  /* all tags (replace previous tags, title/artist/etc. might change
   * in the middle of a stream, e.g. with radio streams) */
  // Returns: (transfer full) (nullable): the new list
  result = gst_tag_list_merge (tagcache_, tag_list,
                                   GST_TAG_MERGE_REPLACE);


  //new tags equals to old ones, nothing interesting  just return
  if (tagcache_ && result 
      && gst_tag_list_is_equal (result/*new-tags*/, tagcache_/*old-tags*/)) 
  {
      gst_tag_list_unref (result);
      // GST_WARNING ("Pipeline sent %s tags update with no changes", type);

                      printf("(bvw_update_tags) Pipeline sent %s tags update with no changes \n", type==StreamType::STREAM_TYPE_AUDIO?"audio":"video");

      return;
  }
  g_clear_pointer (&tagcache_, gst_tag_list_unref);
  //cache tag whether it is audio or video
  tagcache_ = result;
  // GST_DEBUG ("Tags: %" GST_PTR_FORMAT, tag_list);


  /* Dispatching to media-type-specific tags */
  if (type == StreamType::STREAM_TYPE_VIDEO) 
  {
    tags_target = property_our_audio_tags_.get_value();
    cache = &tags_target;
  } 
  else if (type == StreamType::STREAM_TYPE_AUDIO) 
  {
    tags_target = property_our_video_tags_.get_value();
    cache = &tags_target;
  }
  if (cache && *cache) 
  {
    // Returns: (transfer full) (nullable): the new list
    result = gst_tag_list_merge (*cache, tag_list, GST_TAG_MERGE_REPLACE);
    if (*cache)
    {
      gst_tag_list_unref (*cache);
    }

    if(type == StreamType::STREAM_TYPE_VIDEO)
    {
      property_our_video_tags_.set_value(result);
    }
    else if (type == StreamType::STREAM_TYPE_AUDIO)
    {
      property_our_audio_tags_.set_value(result);
    }

  }

                      printf("(bvw_update_tags) gain %s Tags: %" GST_PTR_FORMAT " \n", type==StreamType::STREAM_TYPE_AUDIO?"audio":"video",  
                          static_cast<void*>(tag_list));

    // dont cleanup, we never use ref() on it
  // /* clean up */
  // if (tag_list)
  // {
  //   gst_tag_list_unref (tag_list);
  // }

printf ("(bvw_update_tags) emit got-metadata \n");

  // g_signal_emit (bvw, bvw_signals[SIGNAL_GOT_METADATA], 0);
  //let totem to retrieve metadata (call get_metadata() ... )
  signal_got_metadata_.emit();

  /*set backgronud for player page, video , audio-only , or broken video alert*/
  set_current_actor();

}



//idx of current-video/audio 
gint BaconVideoWidget::Impl::get_current_stream_num(StreamType stream_type)
{
  gint stream_num = -1;

  if(pipeline_ == NULL)
  {
    return stream_num;
  }

  //get stream num
  if(stream_type == StreamType::STREAM_TYPE_AUDIO)
  {
      stream_num = audio_channels_ ? audio_channels_->len : 0;
  }
  else if(stream_type == StreamType::STREAM_TYPE_VIDEO)
  {
      stream_num = video_channels_ ? video_channels_->len : 0;
  }

  // GST_LOG ("current %s stream: %d", stream_type, stream_num);
  return stream_num;

}


//stream_type - "video" or "audio"
GstTagList* BaconVideoWidget::Impl::get_tags_of_current_stream(StreamType stream_type)
{
  GstTagList *tags = NULL;
  gint stream_num = -1;
  GstPad *pad;

  stream_num = get_current_stream_num(stream_type);

  if (stream_num < 0)
  {
    return NULL;
  }
  
  //get tags
  if(stream_type == StreamType::STREAM_TYPE_AUDIO)
  {
      // g_object_get (bvw, "cur-audio-tags", &tags, NULL);
      tags = property_our_audio_tags_.get_value();
  }
  else if (stream_type == StreamType::STREAM_TYPE_VIDEO)
  {
      // g_object_get (bvw, "cur-video-tags", &tags, NULL);
      tags = property_our_video_tags_.get_value();
  }

  // GST_LOG ("current %s stream tags %" GST_PTR_FORMAT, stream_type, tags);
  return tags;
}


void BaconVideoWidget::Impl::get_metadata_string(BvwMetadataType type, Glib::ValueBase& value)
{
  char *string = NULL;
  gboolean res = FALSE;

  value.init(Glib::Value<Glib::ustring>::value_type());

  if (pipeline_ == NULL) {
    Glib::Value<Glib::ustring> string_val;  // Temporary typed value
    string_val.init(Glib::Value<Glib::ustring>::value_type());                      
    Glib::ustring ustr(""); 
    string_val.set(ustr);                
    value = string_val;      
    return;
  }

  switch (type) {
    case BVW_INFO_TITLE:
    //not sure title is in audio or video tags, so use tagcache_ 
      if (tagcache_ != NULL) {
        res = gst_tag_list_get_string_index (tagcache_,
                                             GST_TAG_TITLE, 0, &string);
      }
      break;
    case BVW_INFO_ARTIST:
      if (tagcache_ != NULL) {
        res = gst_tag_list_get_string_index (tagcache_,
                                             GST_TAG_ARTIST, 0, &string);
      }
      break;
    case BVW_INFO_YEAR:
      if (tagcache_ != NULL) {
        GDate *date;
        GstDateTime *datetime;

        if ((res = gst_tag_list_get_date (tagcache_,
                                          GST_TAG_DATE, &date))) {
          string = g_strdup_printf ("%d", g_date_get_year (date));
          g_date_free (date);
        } else if ((res = gst_tag_list_get_date_time (tagcache_,
                                                      GST_TAG_DATE_TIME, &datetime))) {
          string = g_strdup_printf ("%d", gst_date_time_get_year (datetime));
          gst_date_time_unref (datetime);
        }
      }
      break;
    case BVW_INFO_COMMENT:
      if (tagcache_ != NULL) {
        res = gst_tag_list_get_string_index (tagcache_,
                                             GST_TAG_COMMENT, 0, &string);

        /* Use the Comment; if that fails, use Description as specified by:
         * http://xiph.org/vorbis/doc/v-comment.html */
        if (!res) {
          res = gst_tag_list_get_string_index (tagcache_,
                                               GST_TAG_DESCRIPTION, 0, &string);
        }
      }
      break;
    case BVW_INFO_ALBUM:
      if (tagcache_ != NULL) {
        res = gst_tag_list_get_string_index (tagcache_,
                                             GST_TAG_ALBUM, 0, &string);
      }
      break;
    case BVW_INFO_CONTAINER:
      if (tagcache_ != NULL) {
        res = gst_tag_list_get_string_index (tagcache_,
                                             GST_TAG_CONTAINER_FORMAT, 0, &string);
      }
      break;
    case BVW_INFO_VIDEO_CODEC: {
      GstTagList *tags;

      /* try to get this from the stream info first */
      if ((tags = get_tags_of_current_stream(StreamType::STREAM_TYPE_VIDEO))) {
        res = gst_tag_list_get_string (tags, GST_TAG_CODEC, &string);
	gst_tag_list_unref (tags);
      }

      /* if that didn't work, try the aggregated tags */
      if (!res && tagcache_ != NULL) {
        res = gst_tag_list_get_string (tagcache_,
            GST_TAG_VIDEO_CODEC, &string);
      }
      break;
    }
    case BVW_INFO_AUDIO_CODEC: {
      GstTagList *tags;

      /* try to get this from the stream info first */
      if ((tags = get_tags_of_current_stream (StreamType::STREAM_TYPE_AUDIO))) {
        res = gst_tag_list_get_string (tags, GST_TAG_CODEC, &string);
	gst_tag_list_unref (tags);
      }

      /* if that didn't work, try the aggregated tags */
      if (!res && tagcache_ != NULL) {
        res = gst_tag_list_get_string (tagcache_,
            GST_TAG_AUDIO_CODEC, &string);
      }
      break;
    }
    case BVW_INFO_AUDIO_CHANNELS: {
      GstStructure *s;
      GstCaps *caps;

      /*get audio channel, so query audio bin in pipeline*/
      caps = get_caps_of_current_stream(StreamType::STREAM_TYPE_AUDIO);
      if (caps) 
      {
              // printf ("(bvw_get_metadata_string) Ok to get BVW_INFO_AUDIO_CHANNELS\n");
        gint channels = 0;

        s = gst_caps_get_structure (caps, 0);
        if ((res = gst_structure_get_int (s, "channels", &channels))) {
          /* FIXME: do something more sophisticated - but what? */
          if (channels > 2 && audio_caps_have_LFE(s)) {
            string = g_strdup_printf ("%s %d.1", "Surround", channels - 1);
          } else if (channels == 1) {
            string = g_strdup ("Mono");
          } else if (channels == 2) {
            string = g_strdup ("Stereo");
          } else {
            string = g_strdup_printf ("%d", channels);
          }
        }
        gst_caps_unref (caps);
      }else{
              // printf ("(bvw_get_metadata_string) Failed to get BVW_INFO_AUDIO_CHANNELS\n");

      }
      break;
    }

    case BVW_INFO_DURATION:
    case BVW_INFO_TRACK_NUMBER:
    case BVW_INFO_HAS_VIDEO:
    case BVW_INFO_DIMENSION_X:
    case BVW_INFO_DIMENSION_Y:
    case BVW_INFO_VIDEO_BITRATE:
    case BVW_INFO_FPS:
    case BVW_INFO_HAS_AUDIO:
    case BVW_INFO_AUDIO_BITRATE:
    case BVW_INFO_AUDIO_SAMPLE_RATE:
      /* Not strings */
    default:
      g_assert_not_reached ();
    }

  /* Remove line feeds */
  if (string && strstr (string, "\n") != NULL)
    g_strdelimit (string, "\n", ' ');
  if (string != NULL)
    string = g_strstrip (string);

  if (res && string && *string != '\0' && g_utf8_validate (string, -1, NULL)) {
    // g_value_take_string (value, string);

    Glib::Value<Glib::ustring> string_val;  // Temporary typed value
    string_val.init(Glib::Value<Glib::ustring>::value_type()); 
    Glib::ustring ustr = string;      
    string_val.set(ustr);
    value = string_val;  //copy assignment, previous holding will destructs
    g_free (string);


  } 
  //if there are errors in string
  else 
  {
    Glib::Value<Glib::ustring> string_val;  // Temporary typed value
    string_val.init(Glib::Value<Glib::ustring>::value_type());                      
    Glib::ustring ustr("");      
    string_val.set(ustr);                
    value = string_val;                    
    g_free (string);
  }

  return;
}

void BaconVideoWidget::Impl::get_metadata_int (BvwMetadataType type, Glib::ValueBase& value)
{
  int integer = 0;

  value.init( Glib::Value<int>::value_type());


  GstTagList* audio_tags = property_our_audio_tags_.get_value();
  GstTagList* video_tags = property_our_video_tags_.get_value();

  if (pipeline_ == NULL) {
    Glib::Value<int> int_val;  // Temporary typed value
    int_val.init(Glib::Value<int>::value_type());                      
    int_val.set(0);                
    value = int_val;      
    return;
  }

  switch (type) {
    case BVW_INFO_DURATION:
      integer = update_and_get_stream_length() / 1000;
      break;
    case BVW_INFO_TRACK_NUMBER:
      if (tagcache_ == NULL)
        break;
      if (!gst_tag_list_get_uint (tagcache_,
                                  GST_TAG_TRACK_NUMBER, (guint *) &integer))
        integer = 0;
      break;
    case BVW_INFO_DIMENSION_X:
      integer = video_width_;
      break;
    case BVW_INFO_DIMENSION_Y:
      integer = video_height_;
      break;
    case BVW_INFO_AUDIO_BITRATE:
      if (audio_tags == NULL)
        break;
      if (gst_tag_list_get_uint (audio_tags, GST_TAG_BITRATE,
          (guint *)&integer) ||
          gst_tag_list_get_uint (audio_tags, GST_TAG_NOMINAL_BITRATE,
          (guint *)&integer)) {
        integer /= 1000;
      }
      break;
    case BVW_INFO_VIDEO_BITRATE:
      if (video_tags == NULL)
        break;
      if (gst_tag_list_get_uint (video_tags, GST_TAG_BITRATE,
          (guint *)&integer) ||
          gst_tag_list_get_uint (video_tags, GST_TAG_NOMINAL_BITRATE,
          (guint *)&integer)) {
        integer /= 1000;
      }
      break;
    case BVW_INFO_AUDIO_SAMPLE_RATE: {
      GstStructure *s;
      GstCaps *caps;

      caps = get_caps_of_current_stream(StreamType::STREAM_TYPE_AUDIO);
      if (caps) {
              // printf ("(bvw_get_metadata_int) Ok to get BVW_INFO_AUDIO_SAMPLE_RATE\n");

        s = gst_caps_get_structure (caps, 0);
        gst_structure_get_int (s, "rate", &integer);
        gst_caps_unref (caps);
      }else {
              // printf ("(bvw_get_metadata_int) Failed to get BVW_INFO_AUDIO_SAMPLE_RATE\n");
      }
      break;
    }

    case BVW_INFO_TITLE:
    case BVW_INFO_ARTIST:
    case BVW_INFO_YEAR:
    case BVW_INFO_COMMENT:
    case BVW_INFO_ALBUM:
    case BVW_INFO_CONTAINER:
    case BVW_INFO_HAS_VIDEO:
    case BVW_INFO_VIDEO_CODEC:
    case BVW_INFO_HAS_AUDIO:
    case BVW_INFO_AUDIO_CODEC:
    case BVW_INFO_AUDIO_CHANNELS:
      /* Not ints */
    default:
      g_assert_not_reached ();
    }

    Glib::Value<int> int_val;  // Temporary typed value
    int_val.init(Glib::Value<int>::value_type());                      
    int_val.set(integer);                
    value = int_val;  //copy assignment, previous holding will destructs

  return;
}

void BaconVideoWidget::Impl::get_metadata_bool (BvwMetadataType type, Glib::ValueBase& value)
{
  bool boolean = FALSE;

  value.init( Glib::Value<bool>::value_type());

  if (pipeline_ == NULL) {
    Glib::Value<bool> bool_val;  // Temporary typed value
    bool_val.init(Glib::Value<bool>::value_type());                      
    bool_val.set(false);                
    value = bool_val;      
    return;
  }

  // GST_DEBUG ("tagcache  = %" GST_PTR_FORMAT, tagcache_);

  switch (type)
  {
    case BVW_INFO_HAS_VIDEO:
      boolean = media_has_video_;
      break;
    case BVW_INFO_HAS_AUDIO:
      boolean = media_has_audio_;
      break;

    case BVW_INFO_TITLE:
    case BVW_INFO_ARTIST:
    case BVW_INFO_YEAR:
    case BVW_INFO_COMMENT:
    case BVW_INFO_ALBUM:
    case BVW_INFO_DURATION:
    case BVW_INFO_TRACK_NUMBER:
    case BVW_INFO_CONTAINER:
    case BVW_INFO_DIMENSION_X:
    case BVW_INFO_DIMENSION_Y:
    case BVW_INFO_VIDEO_BITRATE:
    case BVW_INFO_VIDEO_CODEC:
    case BVW_INFO_FPS:
    case BVW_INFO_AUDIO_BITRATE:
    case BVW_INFO_AUDIO_CODEC:
    case BVW_INFO_AUDIO_SAMPLE_RATE:
    case BVW_INFO_AUDIO_CHANNELS:
      /* Not bools */
    default:
      g_assert_not_reached ();
  }

  Glib::Value<bool> bool_val;  // Temporary typed value
  bool_val.init(Glib::Value<bool>::value_type());                      
  bool_val.set(boolean);                
  value = bool_val; //copy assignment, previous holding will destructs

  return;
}



void BaconVideoWidget::get_metadata(BvwMetadataType type, Glib::ValueBase& value)
{
  impl_->get_metadata(type, value);
}
void BaconVideoWidget::Impl::get_metadata(BvwMetadataType type, Glib::ValueBase& value)
{
                  // printf("In bacon_video_widget_get_metadata \n");
  switch (type)
  {
    case BVW_INFO_TITLE:
    case BVW_INFO_ARTIST:
    case BVW_INFO_YEAR:
    case BVW_INFO_COMMENT:
    case BVW_INFO_ALBUM:
    case BVW_INFO_CONTAINER:
    case BVW_INFO_VIDEO_CODEC:
    case BVW_INFO_AUDIO_CODEC:
    case BVW_INFO_AUDIO_CHANNELS:
    {
      get_metadata_string(type, value);
    }
      break;
    case BVW_INFO_DURATION:
    case BVW_INFO_DIMENSION_X:
    case BVW_INFO_DIMENSION_Y:
    case BVW_INFO_AUDIO_BITRATE:
    case BVW_INFO_VIDEO_BITRATE:
    case BVW_INFO_TRACK_NUMBER:
    case BVW_INFO_AUDIO_SAMPLE_RATE:
    {
      get_metadata_int(type, value);
    }
      break;
    case BVW_INFO_HAS_VIDEO:
    case BVW_INFO_HAS_AUDIO:
    {
      get_metadata_bool(type, value);
    }
      break;
    case BVW_INFO_FPS:
    {
	      float fps = 0.0;

        if (video_fps_d_ > 0)
            fps = (float) video_fps_n_ / (float) video_fps_d_;

        Glib::Value<float> float_val;
        float_val.init(Glib::Value<float>::value_type());
        float_val.set(fps);
        value = float_val;
    }
      break;
    default:
      g_return_if_reached();
  }

  return;
}




//set picture color balance (preferences dialog)
/* Search for the color balance channel corresponding to type and return it. */
GstColorBalanceChannel* BaconVideoWidget::Impl::get_color_balance_channel(GstColorBalance* color_balance, BvwVideoProperty type)
{
  const GList *channels;

  channels = gst_color_balance_list_channels (color_balance);

  for (; channels != NULL; channels = channels->next) 
  {
    GstColorBalanceChannel *c = static_cast<GstColorBalanceChannel*>(channels->data);

    if (type == BvwVideoProperty::BVW_VIDEO_BRIGHTNESS && g_strrstr (c->label, "BRIGHTNESS"))
      return g_object_ref (c);
    else if (type == BvwVideoProperty::BVW_VIDEO_CONTRAST && g_strrstr (c->label, "CONTRAST"))
      return g_object_ref (c);
    else if (type == BvwVideoProperty::BVW_VIDEO_SATURATION && g_strrstr (c->label, "SATURATION"))
      return g_object_ref (c);
    else if (type == BvwVideoProperty::BVW_VIDEO_HUE && g_strrstr (c->label, "HUE"))
      return g_object_ref (c);
  }

  return NULL;
}




//Actually no Use, we use Gsettings to set video property at inital, this method just for explicitly return the video property
int BaconVideoWidget::Impl::get_video_property(BvwVideoProperty type)
{
  GstColorBalanceChannel *found_channel = NULL;
  int ret, cur;

  g_return_val_if_fail (glsinkbin_ != NULL, 65535/2);

  ret = 0;

  found_channel = get_color_balance_channel (GST_COLOR_BALANCE (glsinkbin_), type);
  cur = gst_color_balance_get_value (GST_COLOR_BALANCE (glsinkbin_), found_channel);

  // GST_DEBUG ("channel %s: cur=%d, min=%d, max=%d", found_channel->label,
	//      cur, found_channel->min_value, found_channel->max_value);

  ret = floor (0.5 +
	       ((double) cur - found_channel->min_value) * 65535 /
	       ((double) found_channel->max_value - found_channel->min_value));

  // GST_DEBUG ("channel %s: returning value %d", found_channel->label, ret);
  g_object_unref (found_channel);
  return ret;
}



void BaconVideoWidget::Impl::set_video_property(BvwVideoProperty type, int value)
{
  GstColorBalanceChannel *found_channel = NULL;
  int i_value;

  g_return_if_fail (glsinkbin_ != NULL);

  // GST_DEBUG ("set video property type %d to value %d", type, value);

  if (!(value <= 65535 && value >= 0))
  {
    return;
  }

  found_channel = get_color_balance_channel (GST_COLOR_BALANCE (glsinkbin_), type);
  i_value = floor (0.5 + value * ((double) found_channel->max_value -
				  found_channel->min_value) / 65535 + found_channel->min_value);

  // GST_DEBUG ("channel %s: set to %d/65535", found_channel->label, value);

  gst_color_balance_set_value (GST_COLOR_BALANCE (glsinkbin_), found_channel, i_value);

  // GST_DEBUG ("channel %s: val=%d, min=%d, max=%d", found_channel->label,
	//      i_value, found_channel->min_value, found_channel->max_value);

  g_object_unref (found_channel);

  // GST_DEBUG ("setting value %d", value);
}













//set audio out type (preferences dialog)

gint BaconVideoWidget::Impl::get_num_audio_channels()
{
  gint channels;

  switch (speakersetup_) {
    case BVW_AUDIO_SOUND_STEREO:
      channels = 2;
      break;
    case BVW_AUDIO_SOUND_4CHANNEL:
      channels = 4;
      break;
    case BVW_AUDIO_SOUND_5CHANNEL:
      channels = 5;
      break;
    case BVW_AUDIO_SOUND_41CHANNEL:
      /* so alsa has this as 5.1, but empty center speaker. We don't really
       * do that yet. ;-). So we'll take the placebo approach. */
    case BVW_AUDIO_SOUND_51CHANNEL:
      channels = 6;
      break;
    case BVW_AUDIO_SOUND_AC3PASSTHRU:
    default:
      g_return_val_if_reached (-1);
  }

  return channels;
}


GstCaps * BaconVideoWidget::Impl::fixate_to_num (const GstCaps * in_caps, gint channels)
{
  int n, count;
  GstStructure *s;
  const GValue *v;
  GstCaps *out_caps = NULL;

  //init to 0
  count = 0;

  if(in_caps)
  {
    out_caps = gst_caps_copy (in_caps);
    //gst_caps_get_size  -  Gets the number of structures contained in the first arg .
    count = gst_caps_get_size (out_caps);

  }

  for (n = 0; n < count; n++) {
    //GstStructure holds key-value pairs.
    s = gst_caps_get_structure (out_caps, n);
    //the number of audio channels in an audio stream
    v = gst_structure_get_value (s, "channels");
    if (!v)
      continue;
    /* get channel count (or list of ~) */
    //gst_structure_fixate_field_nearest_int not worked,it need channels field to be list or range, not just a integer
    // gboolean fixated = gst_structure_fixate_field_nearest_int (s, "channels", channels);
    gst_structure_set (s, "channels", G_TYPE_INT, channels, NULL);

        printf("(bvw/fixate_to_num) channels value is %d\n", channels);
          
        // Since `s` is just a reference to the internal structure, we should not append it directly.
        // Instead, we should copy it, modify it, and append the new one.
        GstStructure *modified_s = gst_structure_copy(s); // Make a copy of the structure
        gst_caps_remove_structure(out_caps, n);  // Remove the old structure
        gst_caps_append_structure(out_caps, modified_s);  // Append the new structure

  }

  return out_caps;
}

void BaconVideoWidget::Impl::set_audio_filter()
{
  gint channels;
  GstCaps *caps, *res;
  GstPad *pad, *peer_pad;

  /* reset old */
  if(audio_capsfilter_)
    g_object_set (audio_capsfilter_, "caps", NULL, NULL);

  /* construct possible caps to filter down to our chosen caps */
  /* Start with what the audio sink supports, but limit the allowed
   * channel count to our speaker output configuration */
  pad = gst_element_get_static_pad (audio_capsfilter_, "src");
  // return the pad that is connected to it,
  peer_pad = gst_pad_get_peer (pad);
  gst_object_unref (pad);
  
  caps = gst_pad_get_current_caps (peer_pad);

      if(caps == NULL)
      {
        printf("(bvw/set_audio_filter) caps is NULL \n");
      }
      else
      {
          gchar *caps_str;
          caps_str = gst_caps_to_string(caps);
          printf("(set_audio_filter): Pad capabilities: %s\n", caps_str);
          g_free(caps_str);
      }

  if(peer_pad){
    gst_object_unref (peer_pad);
  }

  if ((channels = get_num_audio_channels()) == -1)
  {
    return;
  }

  res = fixate_to_num (caps, channels);
  if(caps){
    gst_caps_unref (caps);
  }

  if(res)
  {
          gchar *caps_str;
          caps_str = gst_caps_to_string(res);
          printf("(set_audio_filter): Pad capabilities of res: %s\n", caps_str);
          g_free(caps_str);
  }

  /* set */
  if (res && gst_caps_is_empty (res)) {
    gst_caps_unref (res);
    res = NULL;
  }
  g_object_set (audio_capsfilter_, "caps", res, NULL);

  if (res) {
    gst_caps_unref (res);
  }

  /* reset */
  // pad = gst_element_get_static_pad (audio_capsfilter_, "src");
  // gst_pad_set_caps (pad, NULL);
  // gst_object_unref (pad);
}


void BaconVideoWidget::Impl::set_audio_output_type(BvwAudioOutputType type)
{
  if (type == speakersetup_)
    return;
  else if (type == BVW_AUDIO_SOUND_AC3PASSTHRU)
    return;

  speakersetup_ = type;

  set_audio_filter();
}






//seek

bool BaconVideoWidget::update_and_get_seekable()
{
  return impl_->update_and_get_seekable();
}
bool BaconVideoWidget::Impl::update_and_get_seekable()
{
  gboolean res;
  gint old_seekable;

  g_return_val_if_fail(GST_IS_ELEMENT(pipeline_), FALSE);

  if (cur_video_fileidx_within_tor_ == -1)
  {
    return FALSE;
  }

  //[Old] Caching old value
  old_seekable = seekable_;

  // seekable_'s inital value is -1, which means unknown,not set
  // if seekable_ is not -1, which means it has already been set, don't bother to call gst query for querying seeking 
  // [Make sure only set in the first time]
  if (seekable_ == -1) 
  {
    GstQuery *query;

    query = gst_query_new_seeking (GST_FORMAT_TIME);
    if (gst_element_query (pipeline_, query)) 
    {
        gst_query_parse_seeking (query, NULL, &res, NULL, NULL);

                            printf ("(bacon_video_widget_update_and_get_seekable) seeking query says the stream is%s seekable \n", (res) ? "" : " not");

        seekable_ = (res) ? 1 : 0;
    } 
    else 
    {
      //here we failed to call gst_element_query(), so seekable_ still kept as "-1"
                            // printf("(bacon_video_widget_update_and_get_seekable) seeking query failed \n");
    }
    gst_query_unref (query);
  }

  // whether call gst_element_query for querying seekable or not, as long as seekable_ is set value on it (TRUE OR FALSE)
  // return the seekable value (TRUE or FALSE)
  if (seekable_ != -1) 
  {
    res = (seekable_ != 0);
    goto done;
  }

  /* if still can't get the seekable state, Try to guess from duration. if we can get stream_length, count it as seekable  
    This is very unreliable though so don't save it */
  //stream_length_ is "zero", which is initial value, means that we do not get the stream_length yet
  if (stream_length_ == 0) {
    res = (update_and_get_stream_length() > 0);
  } else {
    res = (stream_length_ > 0);
  }


done:
  //notify seekable has changed
  //case 1: old_seekable is -1, seekable_ is 1, this is video become seekable
  //case 2: old_seekable is 1, seekable_ is 0, this is video become un-seekable
  //case 3: old_seekable is 0, seekable_ is 1, this is video become re-seekable
  if (old_seekable != seekable_)
  {
    //let Totem's property_notify_cb_seekable be called
    // g_object_notify (G_OBJECT (bvw), "seekable");
    property_seekable_.notify();
  }

                            // printf("(bacon_video_widget_update_and_get_seekable) stream is%s seekable \n", res ? "" : " not");

  // GST_DEBUG ("stream is%s seekable", (res) ? "" : " not");
  return res;
}






bool BaconVideoWidget::can_direct_seek()
{
  return impl_->can_direct_seek();
}
bool BaconVideoWidget::Impl::can_direct_seek()
{
  g_return_val_if_fail (GST_IS_ELEMENT(pipeline_), FALSE);

  if (cur_video_fileidx_within_tor_ == -1)
    return FALSE;

  return TRUE;
}


bool BaconVideoWidget::Impl::seek_time_no_lock(gint64 _time, GstSeekFlags flag, GError **error)
{
  //set play direction to forward
  if (set_playback_direction(TRUE) == FALSE)
    return FALSE;

  //reset seek_time to -1 
  seek_time_ = -1;

  GstState cur_state;
  gst_element_get_state (pipeline_, &cur_state, NULL, 0);
            printf ("(bacon_video_widget_seek_time_no_lock) SET pipeline_ state to PAUSED, cur_state:%s\n",gst_element_state_get_name (cur_state));
  if (cur_state != GST_STATE_PAUSED) {
    //Pausing the pipeline before doing a seek
    gst_element_set_state(pipeline_, GST_STATE_PAUSED);
  }

                  printf ("(bacon_video_widget_seek_time_no_lock) Call gst_element_seek on pipeline \n");

  //Flushing seeks will trigger a preroll, which will emit GST_MESSAGE_ASYNC_DONE
  gst_element_seek (pipeline_, rate_,
		    GST_FORMAT_TIME, static_cast<GstSeekFlags>(GST_SEEK_FLAG_FLUSH | flag),
		    GST_SEEK_TYPE_SET, _time * GST_MSECOND,
		    GST_SEEK_TYPE_NONE, GST_CLOCK_TIME_NONE);

  return TRUE;

}





bool BaconVideoWidget::seek_time(std::int64_t _time, bool accurate, GError **error)
{
  return impl_->seek_time(_time, accurate, error);
}
bool BaconVideoWidget::Impl::seek_time(std::int64_t _time, bool accurate, GError **error)
{
  GstClockTime cur_time;
  GstSeekFlags  flag;

  g_return_val_if_fail(GST_IS_ELEMENT(pipeline_), FALSE);


  // GST_LOG ("Seeking to %" GST_TIME_FORMAT, GST_TIME_ARGS (_time * GST_MSECOND));

  
  /* Don't say we'll seek past the end */
  _time = MIN (_time, stream_length_);

          printf("(bacon_video_widget_seek_time) Seeking to %" GST_TIME_FORMAT " \n", GST_TIME_ARGS (_time * GST_MSECOND));

  /* Emit a time tick of where we are going, we are gonna paused */
  got_time_tick(pipeline_, _time * GST_MSECOND);

  /* Is there a pending seek? if so, block on the seek_mutex*/
  g_mutex_lock(&seek_mutex_);/********************************************/


  //If user seeks to multiple time very concurrently and frequently, will reach the "else" branch, meaning that it is not long enough since previous seek
  //which means that the times you want to seek will not be responded right away,they will be neglected
  /*
  SET seek_req_time_                           SET seek_req_time_     SET seek_time_    SET seek_time_    SET seek_req_time_
  --------|------------------------------------------------------|-----------------|-----------------|--------------------------------|
          |                                                      |                 |                 |                                |
  previous seek                                                 seek1            seek2             seek3                             seek4
                                                      [No pending seek]      [Not long enough]   [Not long enough]       [No pending seek again]
                                                                                *Neglected*         *Neglected*
  */


  /* If there's no pending seek, or
   * it's been too long since the seek,
   * or we don't have an accurate seek requested */
  cur_time = gst_clock_get_internal_time (clock_);
  if (seek_req_time_ == GST_CLOCK_TIME_NONE ||
      cur_time > seek_req_time_ + SEEK_TIMEOUT ||
      accurate) 
  {
            printf("(bacon_video_widget_seek_time) No pending seek, just do it \n");

    //reset seek_time_ back to -1, means there is no pending seek
    seek_time_ = -1;
    //record the seek triggered time
    seek_req_time_ = cur_time;
    g_mutex_unlock(&seek_mutex_);/*****************************************/
  } 


  //During one seek, we got other seeks,just update seek_time_ per newest seek 
  //*if we seeder, GST_MESSAGE_ASYNC_DONE handling run both before/after update newest seek_time code below
  //*if we leecher, we downloading, so GST_MESSAGE_ASYNC_DONE may comes very late, 
  //so during this period, seeks will be ignored (btdemux stream_seek never be called)
  else 
  {
    // GST_LOG ("Not long enough since last seek, queuing it");

              printf("(bacon_video_widget_seek_time) Not long enough since last seek, queuing the newest \n");

    //set seek_time to _time, which is not -1 , means that there is a seek queued  
    seek_time_ = _time;
    g_mutex_unlock(&seek_mutex_);/******************************************/
    return TRUE;
  }


  flag = (accurate ? GST_SEEK_FLAG_ACCURATE : GST_SEEK_FLAG_NONE);
  seek_time_no_lock(_time, flag, error);


  return TRUE;
}


bool BaconVideoWidget::seek(double position, GError **error)
{
  return impl_->seek(position, error);
}


bool BaconVideoWidget::Impl::seek(double position, GError **error)
{
    gint64 seek_pos, length_nanos;

    g_return_val_if_fail(GST_IS_ELEMENT (pipeline_), FALSE);
    g_return_val_if_fail(stream_length_ > 0, FALSE);

    length_nanos = (gint64) (stream_length_ * GST_MSECOND);
    seek_pos = (gint64) (length_nanos * position);

    // GST_LOG ("Seeking to %3.2f%% %" GST_TIME_FORMAT, position,
    //     GST_TIME_ARGS (seek_pos));

                    printf("(bacon_video_widget_seek) Seeking to %3.2f%% %" GST_TIME_FORMAT "\n", position, GST_TIME_ARGS (seek_pos));

    return seek_time(seek_pos / GST_MSECOND, FALSE, error);
}














//play ,pause

bool BaconVideoWidget::is_playing()
{
  return impl_->is_playing();
}
bool BaconVideoWidget::Impl::is_playing ()
{
  bool ret;

  g_return_val_if_fail (GST_IS_ELEMENT (pipeline_), FALSE);

  ret = (target_state_ == GST_STATE_PLAYING);
  // GST_LOG ("%splaying", (ret) ? "" : "not ");

  return ret;
}




bool BaconVideoWidget::Impl::set_playback_direction(bool forward)
{

  bool is_forward;
  bool retval;
  float target_rate;
  GstEvent *event;
  gint64 cur = 0;

  is_forward = (rate_ > 0.0);
  if (forward == is_forward)
  {
    return TRUE;
  }

  retval = FALSE;
  target_rate = (forward ? FORWARD_RATE : REVERSE_RATE);

  if (gst_element_query_position (pipeline_, GST_FORMAT_TIME, &cur)) 
  {

            printf("(bvw_set_playback_direction) Setting playback direction to %s at %"G_GINT64_FORMAT" \n",
                DIRECTION_STR, cur);

    // GST_DEBUG ("Setting playback direction to %s at %"G_GINT64_FORMAT"", DIRECTION_STR, cur);

    event = gst_event_new_seek (target_rate,
                GST_FORMAT_TIME, static_cast<GstSeekFlags>(GST_SEEK_FLAG_FLUSH | GST_SEEK_FLAG_ACCURATE),
                GST_SEEK_TYPE_SET, forward ? cur : G_GINT64_CONSTANT (0),
                GST_SEEK_TYPE_SET, forward ? G_GINT64_CONSTANT (0) : cur);
    if (gst_element_send_event (pipeline_, event) == FALSE) 
    {
      GST_WARNING ("Failed to set playback direction to %s", DIRECTION_STR);
    } 
    else 
    {
      gst_element_get_state (pipeline_, NULL, NULL, GST_CLOCK_TIME_NONE);
      rate_ = target_rate;
      retval = TRUE;
    }
  } 
  else 
  {
    // GST_LOG ("Failed to query position to set playback to %s", DIRECTION_STR);
    printf("Failed to query position to set playback to %s\n", DIRECTION_STR);
  }

  return retval;
}




void BaconVideoWidget::open(int fileidx)
{
  impl_->open(fileidx);
}
void BaconVideoWidget::Impl::open(int fileidx)
{
  g_return_if_fail (pipeline_ != NULL);
  
  /* So we aren't closed yet... */
  if(cur_video_fileidx_within_tor_ >= 0) 
  {
                printf("(bacon_video_widget_open) So we aren't closed yet...\n");
    close();
  }
                printf("(bacon_video_widget_open) set cur_video_fileidx_within_tor to %d\n", fileidx);
  cur_video_fileidx_within_tor_ = fileidx;

  media_has_video_ = FALSE;
  media_has_unsupported_video_ = FALSE;
  media_has_audio_ = FALSE;

  /* Flush the bus to make sure we don't get any messages
   * from the previous file index torrent pieces pushed by btdemux
   */
  gst_bus_set_flushing (bus_, TRUE);

  gst_bus_set_flushing (bus_, FALSE);

/******************************************************************/
  // set target fileindex of that video within torrent, 
  // so it will pushes pieces resides in that video file
  // let gst_bt_demux.cpp update_requested_stream() called
  g_object_set (btdemux_, "current-video-file-index", fileidx, NULL);
/*******************************************************************/

#if 2
        printf ("(bacon_video_widget_open) reset seekable back to unknown state (which is -1)\n");
#endif

  // reset seekable back to inital value which is "-1", meaning that seekable is unknown (neither TRUE nor FALSE)
  seekable_ = -1;

  clear_missing_plugins_messages();

}



bool BaconVideoWidget::play(GError ** error/*location of error*/)
{
  return impl_->play(error);
}
bool BaconVideoWidget::Impl::play(GError ** error/*location of error*/)
{

                        // printf("(bacon_video_widget_play) \n");

  GstState cur_state;

  g_return_val_if_fail (GST_IS_ELEMENT (pipeline_), FALSE);

  //we must set the valid fileidx desired before set pipieline to playing state, this is guaranteed !
  g_return_val_if_fail (cur_video_fileidx_within_tor_ != -1, FALSE);

  target_state_ = GST_STATE_PLAYING;

  /* Don't try to play if we're already doing that */
  gst_element_get_state (pipeline_, &cur_state, NULL, 0);

                        printf("(bacon_video_widget_play) cur_state:%s\n", gst_element_state_get_name(cur_state));

  if(cur_state == GST_STATE_PLAYING)
  {
    //if already PLYAING state, just bail out;
    return TRUE;
  }

  /* Or when we're buffering (the pieces data needed to streaming is downloading)*/
  if(buffering_ != FALSE) 
  {
    printf ("(bacon_video_widget_play) buffering in progress, not playing \n");
    // GST_DEBUG ("buffering in progress, not playing");
    /* just lie and do nothing in this case */
    return TRUE;
  }

  /* Set direction to forward */
  if(set_playback_direction(TRUE) == FALSE) 
  {
    // GST_DEBUG ("Failed to reset direction back to forward to play");
    g_set_error_literal (error, BVW_ERROR, static_cast<gint>(BVW_ERROR_GENERIC),
      "This file could not be played. Try restarting playback.");
    return FALSE;
  }

  // g_signal_emit (bvw, bvw_signals[SIGNAL_PLAY_STARTING], 0);
  signal_play_starting_.emit();

  // GST_DEBUG ("play");

  //!! state change may not instantly affects, it is done asynchronously, see GST_MESSAGE_STATE_CHANGED
              printf ("(bacon_video_widget_play) SET pipeline_ state to PLAYING\n");

  gst_element_set_state (pipeline_, GST_STATE_PLAYING);
  

  /* will handle all errors asynchroneously */
  return TRUE;

}



void BaconVideoWidget::pause()
{
  impl_->pause();
}
void BaconVideoWidget::Impl::pause()
{
  GstStateChangeReturn ret;
  GstState state;

  g_return_if_fail (GST_IS_ELEMENT (pipeline_));

  /* Get the current state */
  ret = gst_element_get_state (GST_ELEMENT (pipeline_), &state, NULL, 0);

              if (ret != GST_STATE_CHANGE_NO_PREROLL &&
                  ret != GST_STATE_CHANGE_SUCCESS &&
                  state > GST_STATE_READY) 
              {

                      printf("(bacon_video_widget_pause) Stopping because we have a live stream\n");

                // GST_LOG ("Stopping because we have a live stream");

                stop();
                return;
              }

        printf("(bacon_video_widget_pause) Pausing\n");

  // GST_LOG ("Pausing");

  target_state_ = GST_STATE_PAUSED;
  

              printf ("(bacon_video_widget_pause) SET pipeline_ state to PAUSED\n");

  gst_element_set_state (GST_ELEMENT (pipeline_), GST_STATE_PAUSED);
}






void BaconVideoWidget::Impl::stop_play_pipeline()
{
    GstState cur_state;

    gst_element_get_state (pipeline_, &cur_state, NULL, 0);
  
    //Paused or Playing
    if (cur_state > GST_STATE_READY) 
    {
      GstMessage *msg;

      // GST_DEBUG ("stopping");

      printf ("(bvw_stop_play_pipeline) SET pipeline_ state to READY\n");

      gst_element_set_state (pipeline_, GST_STATE_READY);

      /* process all remaining state-change messages so everything gets
      * cleaned up properly (before the state change to NULL flushes them) */
      // GST_DEBUG ("processing pending state-change messages");
      while ((msg = gst_bus_pop_filtered (bus_, GST_MESSAGE_STATE_CHANGED))) 
      {
        gst_bus_async_signal_func (bus_, msg, NULL);
        gst_message_unref (msg);
      }
    }

    /* and now drop all following messages until we start again. The
     * bus is set to flush=false again in bacon_video_widget_open()
    */
    if (bus_)
    {
      gst_bus_set_flushing (bus_, TRUE);
    }

    /* Now in READY or lower */
    target_state_ = GST_STATE_READY;

    /* Clear buffering state */
    buffering_ = FALSE;
   
    g_object_set (video_sink_,
                  "rotate-method", GST_VIDEO_ORIENTATION_AUTO,
                  NULL);

              printf ("(bvw_stop_play_pipeline) stopped\n");

    // GST_DEBUG ("stopped");
}





void BaconVideoWidget::stop()
{
  impl_->stop();
}
void BaconVideoWidget::Impl::stop()
{

  g_return_if_fail (GST_IS_ELEMENT(pipeline_));

                    printf ("(bacon_video_widget_stop) \n");

  // GST_LOG ("Stopping");
  stop_play_pipeline();

  /* Emit a time tick of where we are going and Reset time position (aka, current_time_) to 0 when stopping */
  got_time_tick(GST_ELEMENT(pipeline_), 0);
}




void BaconVideoWidget::close()
{
  impl_->close();
}
void BaconVideoWidget::Impl::close()
{

  g_return_if_fail (GST_IS_ELEMENT (pipeline_));
  
  // GST_LOG ("Closing");
  stop_play_pipeline();


  rate_ = FORWARD_RATE;

  current_time_ = 0;
  seek_req_time_ = GST_CLOCK_TIME_NONE; //reset to undefined clock time
  seek_time_ = -1;
  //reset stream_length_ to "zero", which is initial value, means that we do not get the stream_length yet
  stream_length_ = 0;

  if(eos_tag_.connected() != false)
  {
    eos_tag_.disconnect();
  }


  g_clear_pointer (&tagcache_,  gst_tag_list_unref);
  gst_tag_list_unref(property_our_audio_tags_.get_value());
  property_our_audio_tags_.set_value(NULL);
  gst_tag_list_unref(property_our_video_tags_.get_value());
  property_our_video_tags_.set_value(NULL);


  //notify seekable has changed
  //let totem's property_notify_cb_seekable be called
  // g_object_notify (G_OBJECT (bvw), "seekable");
  property_seekable_.notify();

  //Emit a time tick of where we are going
  got_time_tick(GST_ELEMENT(pipeline_), 0);

}





//volume 


bool BaconVideoWidget::Impl::volume_readback_cb()
{
  std::cout << "volume_readback_cb at initial" << std::endl;
  gdouble vol;

  vol = gst_stream_volume_get_volume (GST_STREAM_VOLUME(volume_plugin_),
                                      GST_STREAM_VOLUME_FORMAT_CUBIC);

  property_volume_.set_value(vol);  

  return FALSE;
}

void BaconVideoWidget::Impl::volume_readback()
{
  Glib::signal_idle().connect(sigc::mem_fun(*this, &Impl::volume_readback_cb));
}


bool BaconVideoWidget::can_set_volume()
{
  return impl_->can_set_volume();
}
bool BaconVideoWidget::Impl::can_set_volume()
{
  g_return_val_if_fail(GST_IS_ELEMENT(pipeline_), FALSE);

  if (speakersetup_ == BVW_AUDIO_SOUND_AC3PASSTHRU)
    return FALSE;

  return TRUE;
}




void BaconVideoWidget::set_volume(double volume)
{
  impl_->set_volume(volume);
}
void BaconVideoWidget::Impl::set_volume(double volume)
{     

                printf("(bacon_video_widget_set_volume) %lf \n", volume);

  g_return_if_fail(GST_IS_ELEMENT(pipeline_));

  if (can_set_volume() != FALSE) 
  {
    volume = CLAMP (volume, 0.0, 1.0);
    gst_stream_volume_set_volume (GST_STREAM_VOLUME(volume_plugin_),
                                  GST_STREAM_VOLUME_FORMAT_CUBIC,
                                  volume);
    volume_readback();
  }
}



double BaconVideoWidget::get_volume()
{
  return impl_->get_volume();
}
double BaconVideoWidget::Impl::get_volume()
{
                printf("(bacon_video_widget_get_volume)\n" );

  g_return_val_if_fail (GST_IS_ELEMENT(pipeline_), 0.0);

  return property_volume_.get_value();
}







//aspect-ratio 
void BaconVideoWidget::set_aspect_ratio (BvwAspectRatio ratio)
{
  impl_->set_aspect_ratio(ratio);
}

//only need set_aspect_ratio, get_aspect_ratio is not needed
void BaconVideoWidget::Impl::set_aspect_ratio (BvwAspectRatio ratio)
{
  ratio_type_ = ratio;

  switch (ratio_type_) {
  case BVW_RATIO_SQUARE:
    g_object_set (video_sink_,
		  "video-aspect-ratio-override", 1, 1,
		  NULL);
    break;
  case BVW_RATIO_FOURBYTHREE:
    g_object_set (video_sink_,
		  "video-aspect-ratio-override", 4, 3,
		  NULL);
    break;
  case BVW_RATIO_ANAMORPHIC:
    g_object_set (video_sink_,
		  "video-aspect-ratio-override", 16, 9,
		  NULL);
    break;
  case BVW_RATIO_DVB:
    g_object_set (video_sink_,
		  "video-aspect-ratio-override", 20, 9,
		  NULL);
    break;
    /* handle these to avoid compiler warnings */
  case BVW_RATIO_AUTO:
  default:
    g_object_set (video_sink_,
		  "video-aspect-ratio-override", 0, 1,
		  NULL);
    break;
  }
}



//rotation (rotation plugin)
void BaconVideoWidget::set_rotation(BvwRotation rotation)
{
  impl_->set_rotation(rotation);
}
void BaconVideoWidget::Impl::set_rotation(BvwRotation rotation)
{
  rotation_ = rotation;
  g_object_set (video_sink_, "rotate-method", rotation, NULL);
}


BvwRotation BaconVideoWidget::get_rotation()
{
  return impl_->get_rotation();
}
BvwRotation BaconVideoWidget::Impl::get_rotation()
{
  return rotation_;
}


namespace
{
  bool float_equal(float a, float b, float epsilon = 1e-5f) {
    return std::abs(a - b) < epsilon;
}
}
// anonymous namespace

//variable-rate (variable-rate plugin)
bool BaconVideoWidget::set_rate (float new_rate)
{
  return impl_->set_rate(new_rate);
}
bool BaconVideoWidget::Impl::set_rate (float new_rate)
{
  GstEvent *event;
  bool retval = FALSE;
  gint64 cur;

  g_return_val_if_fail (GST_IS_ELEMENT (pipeline_), FALSE);

  if(float_equal(new_rate, rate_))
  {
    return TRUE;
  }

  /* set upper and lower bound for rate */
  if (new_rate < BVW_MIN_RATE)
  {
    return retval;
  }
  if (new_rate > BVW_MAX_RATE)
  {
    return retval;
  }

  if (gst_element_query_position (pipeline_, GST_FORMAT_TIME, &cur)) 
  {
    // GST_DEBUG ("Setting new rate at %"G_GINT64_FORMAT"", cur);
          printf ("(bacon_video_widget_set_rate) Setting new rate at %"G_GINT64_FORMAT" \n", cur);
    event = gst_event_new_seek (new_rate,
				GST_FORMAT_TIME, static_cast<GstSeekFlags>(GST_SEEK_FLAG_FLUSH | GST_SEEK_FLAG_ACCURATE),
				GST_SEEK_TYPE_SET, cur,
				GST_SEEK_TYPE_SET, GST_CLOCK_TIME_NONE);
    if (gst_element_send_event (pipeline_, event) == FALSE) 
    {
          printf ("(bacon_video_widget_set_rate) Failed to change rate\n");

      // GST_DEBUG ("Failed to change rate");
    } 
    else 
    {
      // pass NULL to out arg, checking if the call succeeds
      gst_element_get_state (pipeline_, NULL, NULL, GST_CLOCK_TIME_NONE);
      rate_ = new_rate;
      retval = TRUE;
    }
  } 
  else 
  {
          printf ("(bacon_video_widget_set_rate) failed to query position\n");
    
    // GST_DEBUG ("failed to query position");
  }
  return retval;
}




//Whether show cursor when mouse over the BaconVideoWidget area
void BaconVideoWidget::set_show_cursor(bool show_cursor)
{
  impl_->set_show_cursor(show_cursor);
}
void BaconVideoWidget::Impl::set_show_cursor(bool show_cursor)
{
  if (cursor_shown_ == show_cursor)
  {
    return;
  }
  cursor_shown_ = show_cursor;
  update_cursor();
}